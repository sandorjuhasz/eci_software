{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from ecomplexity import ecomplexity\n",
    "from ecomplexity import proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 0 - general data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "selected_period = \"year\"\n",
    "#period_for_complexity = 1\n",
    "log_num_pushers = False\n",
    "\n",
    "# for ecomplexity calculcation\n",
    "key_cols = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"language\",\n",
    "    \"val\": \"num_pushers\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../data/languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter functions\n",
    "def drop_specifics_from_list(data, filter_list):\n",
    "    \"\"\"filter specific languages from list -- motivated by RM del Rio-Chanona et al 2023\"\"\"\n",
    "    data = data[~data[\"language\"].str.contains(filter_list, case=False, regex=True)]\n",
    "    return data\n",
    "\n",
    "def top_languages_filter(data, nr_languages):\n",
    "    \"\"\"keep top x number of languages ONLY\"\"\"\n",
    "    top_languages = data.groupby([\"language\"])[\"num_pushers\"].agg(\"sum\").reset_index().sort_values(by=\"num_pushers\", ascending=False)\n",
    "    top_languages = list(top_languages[\"language\"])[:nr_languages]\n",
    "    data = data[data[\"language\"].isin(top_languages)]\n",
    "    return data\n",
    "    \n",
    "def drop_country_codes_from_list(data, country_list):\n",
    "    data = data[~data[\"iso2_code\"].isin(country_list)]\n",
    "    data = data.dropna(subset=\"iso2_code\")\n",
    "    return data\n",
    "\n",
    "def add_period_ids(data, period):\n",
    "    \"\"\"create missing semester ID and construct different period IDs\"\"\"\n",
    "    if period==\"year\":\n",
    "        year_to_period = dict(zip(data[\"year\"].unique(), list(range(1, len(data[\"year\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"year\"].map(year_to_period)\n",
    "    if period==\"semester\":\n",
    "        data[\"semester\"] = np.where(data[\"quarter\"] <= 2, 1, 2)\n",
    "        data[\"semester_id\"] = data[\"year\"].astype(str).str.cat(data[\"semester\"].astype(str), sep=\"s\")\n",
    "        semester_to_period = dict(zip(data[\"semester_id\"].unique(), list(range(1, len(data[\"semester_id\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"semester_id\"].map(semester_to_period)\n",
    "    if period==\"quarter\":\n",
    "        data[\"quarter_id\"] = data[\"year\"].astype(str).str.cat(data[\"quarter\"].astype(str), sep=\"q\")\n",
    "        quarter_to_period = dict(zip(data[\"quarter_id\"].unique(), list(range(1, len(data[\"quarter_id\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"quarter_id\"].map(quarter_to_period)\n",
    "    return data\n",
    "\n",
    "\n",
    "# probably we can delete later\n",
    "def dataframe_for_ecomplexity(data, period):\n",
    "    \"\"\"aggregate and transform dataframe for ecomplexity functions\"\"\"\n",
    "    #data = data[(data[\"year\"]==focal_year) & (data[\"quarter\"].isin(quarter_list))]\n",
    "    data = data[(data[\"period\"]==period)]\n",
    "    data = data\\\n",
    "        .groupby([\"period\", \"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\\\n",
    "        .sort_values(by=\"num_pushers\", ascending=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84934, 7)\n"
     ]
    }
   ],
   "source": [
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the log of num_pushers\n",
    "if log_num_pushers == True:\n",
    "    df[\"num_pushers\"] = np.log10(df[\"num_pushers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 - M_{cl} - relatedness - complexity - 2020-2021**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle data for M_{cl}\n",
    "def bundle_data(data, periods):\n",
    "    data = data[data[\"period\"].isin(periods)]\\\n",
    "        .groupby([\"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\n",
    "    data[\"period\"] = 1\n",
    "    return data\n",
    "\n",
    "dfb = bundle_data(df, periods=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# software complexity calculation\n",
    "cdf = ecomplexity(dfb, key_cols)\n",
    "#cdf.to_csv(\"../outputs/software_complexity_2020_2021_based_log.csv\", index=False, sep=\";\")\n",
    "cdf.to_csv(\"../outputs/software_complexity_2020_2021_based.csv\", index=False, sep=\";\")\n",
    "\n",
    "# github space\n",
    "space_df = proximity(dfb, key_cols)\n",
    "space_df.to_csv(\"../outputs/software_space_2020_2021_based.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf.drop_duplicates(subset=\"language\").sort_values(by=\"pci\").tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get relatedness network from raw proximity values\n",
    "\n",
    "def edgelist_for_github_space(data, key_columns):\n",
    "    \"\"\"transform the ecomplexity proximity output for visualization\"\"\"\n",
    "    data = data[key_columns]\n",
    "\n",
    "    # drop zero -- non-existing edges\n",
    "    data = data[data[key_columns[2]] > 0]\n",
    "\n",
    "    # drop self loops\n",
    "    data = data[data[key_columns[0]] != data[key_columns[1]]]\n",
    "    return data\n",
    "\n",
    "def maximum_spanning_tree(data, key_columns):\n",
    "    table = data.copy()\n",
    "    table[\"distance\"] = 1.0 / table[key_columns[2]]\n",
    "    G = nx.from_pandas_edgelist(table, source = key_columns[0], target = key_columns[1], edge_attr = [\"distance\", key_columns[2]])\n",
    "    T = nx.minimum_spanning_tree(G, weight = \"distance\")\n",
    "    table2 = nx.to_pandas_edgelist(T)\n",
    "    table2 = table2[table2[key_columns[2]] > 0]\n",
    "    table2.rename(columns = {\"source\": key_columns[0], \"target\": key_columns[1], key_columns[2]: \"score\"}, inplace = True)\n",
    "    table = pd.merge(\n",
    "        table,\n",
    "        table2,\n",
    "        on=key_columns[0:2]\n",
    "    )  \n",
    "    table[\"edge\"] = table.apply(lambda x: \"%s-%s\" % (min(x[key_columns[0]], x[key_columns[1]]), max(x[key_columns[0]], x[key_columns[1]])), axis = 1)\n",
    "    table = table.drop_duplicates(subset = [\"edge\"])\n",
    "    table = table.drop(\"edge\", 1)\n",
    "    return table[key_columns]\n",
    "\n",
    "def add_edges(mst_edges, all_edges, nr_edges_to_add):\n",
    "    # drop mst edges from the full edgelist\n",
    "    mst_edges[\"drop\"] = 1\n",
    "    all_edges = pd.merge(\n",
    "        all_edges,\n",
    "        mst_edges,\n",
    "        on = [\"language_1\", \"language_2\", \"proximity\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    all_edges = all_edges[all_edges[\"drop\"] != 1].drop(columns=\"drop\")\n",
    "\n",
    "    # sort and select\n",
    "    all_edges = all_edges.sort_values(by=\"proximity\", ascending=False).iloc[:nr_edges_to_add]\n",
    "\n",
    "    # add to mst edgelist\n",
    "    software_space_el = pd.concat([mst_el, all_edges])\n",
    "    return software_space_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/156599475.py:29: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  table = table.drop(\"edge\", 1)\n"
     ]
    }
   ],
   "source": [
    "# from space table to MST w/ additional edges\n",
    "space_table = edgelist_for_github_space(space_df, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_el = maximum_spanning_tree(space_table, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_graph = nx.from_pandas_edgelist(mst_el, source=\"language_1\", target=\"language_2\")\n",
    "n_nodes = mst_graph.number_of_nodes()\n",
    "n_edges = n_nodes * 2\n",
    "software_space_el = add_edges(mst_el, space_table, nr_edges_to_add=n_edges)\n",
    "\n",
    "# export for Herr Wachs\n",
    "software_space_el.to_csv(\"../outputs/software_space_edgelist_2020_2021_based.csv\", index=False, sep=\";\")\n",
    "#software_space_el.to_csv(\"../outputs/software_space_edgelist_2020_2021_based_log.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 - regression data for cross-sectional entry models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2 -- (2022) -- entry in (2023)\n",
    "\n",
    "# bundle data for M_{cl}\n",
    "dfb3 = bundle_data(df, periods=[3])\n",
    "dfb4 = bundle_data(df, periods=[4])\n",
    "dfb3[\"period\"] = 3\n",
    "dfb4[\"period\"] = 4\n",
    "dfbs = pd.concat([dfb3, dfb4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rca_calculation(table, c_column, p_column, value_column):\n",
    "    \"\"\"calculate RCA from an M_cp dataframe\"\"\"\n",
    "    table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
    "    table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
    "    table[\"e\"] = table[value_column].sum()\n",
    "\n",
    "    table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
    "    table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_88442/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfbs[\"period\"].unique():\n",
    "    rca_df = dfbs[dfbs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\"))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the entry style\n",
    "entry_pattern = [0,1]\n",
    "consider_pattern = [0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "# cdf = pd.read_csv(\"../outputs/complexity_table2020.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#software_space_el = pd.read_csv(\"../outputs/software_space_edgelist2020.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el,\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_entry_regression_version3_2022_2023.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**outdated versions -- will delete later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 -- (2020-2021) -- entry in (2022-2023)\n",
    "\n",
    "# bundle data for M_{cl}\n",
    "def bundle_data(data, periods):\n",
    "    data = data[data[\"period\"].isin(periods)]\\\n",
    "        .groupby([\"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\n",
    "    data[\"period\"] = 1\n",
    "    return data\n",
    "\n",
    "dfb1 = bundle_data(df, periods=[1,2])\n",
    "dfb2 = bundle_data(df, periods=[3,4])\n",
    "dfb2[\"period\"] = 2\n",
    "dfbs = pd.concat([dfb1, dfb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rca_calculation(table, c_column, p_column, value_column):\n",
    "    \"\"\"calculate RCA from an M_cp dataframe\"\"\"\n",
    "    table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
    "    table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
    "    table[\"e\"] = table[value_column].sum()\n",
    "\n",
    "    table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
    "    table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_82306/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfbs[\"period\"].unique():\n",
    "    rca_df = dfbs[dfbs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\"))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the entry style\n",
    "pattern = [0,1]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "# cdf = pd.read_csv(\"../outputs/complexity_table2020.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==1].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#software_space_el = pd.read_csv(\"../outputs/software_space_edgelist2020.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el,\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==1].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "#full_df.to_csv(\"../outputs/data_entry_regression_version1_2023q_added.csv\", index=False, sep=\";\")\n",
    "full_df.to_csv(\"../outputs/data_entry_regression_version1_log.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_entry_regression_version3.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "\n",
    "#full_df.to_csv(\"../outputs/data_entry_regression_version2_2023q_added.csv\", index=False, sep=\";\")\n",
    "#full_df.to_csv(\"../outputs/data_entry_regression_version2_log.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 - panel data for entry regressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 -- semester -- actually a cross-section ...\n",
    "# version 2 -- quarter panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42619, 9)\n"
     ]
    }
   ],
   "source": [
    "# version 1 -- semester panel\n",
    "selected_period = \"semester\"\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = df[df[\"year\"]>2021]\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso2_code</th>\n",
       "      <th>language</th>\n",
       "      <th>period</th>\n",
       "      <th>num_pushers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>3</td>\n",
       "      <td>2.328380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>Assembly</td>\n",
       "      <td>2</td>\n",
       "      <td>2.075547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE</td>\n",
       "      <td>Assembly</td>\n",
       "      <td>3</td>\n",
       "      <td>2.498311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE</td>\n",
       "      <td>Assembly</td>\n",
       "      <td>4</td>\n",
       "      <td>2.240549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE</td>\n",
       "      <td>Batchfile</td>\n",
       "      <td>1</td>\n",
       "      <td>2.748963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25357</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Shell</td>\n",
       "      <td>4</td>\n",
       "      <td>2.501059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25358</th>\n",
       "      <td>ZW</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>1</td>\n",
       "      <td>2.326336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25359</th>\n",
       "      <td>ZW</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>2</td>\n",
       "      <td>2.481443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25360</th>\n",
       "      <td>ZW</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>3</td>\n",
       "      <td>2.522444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25361</th>\n",
       "      <td>ZW</td>\n",
       "      <td>TypeScript</td>\n",
       "      <td>4</td>\n",
       "      <td>2.285557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25362 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iso2_code    language  period  num_pushers\n",
       "0            AD  JavaScript       3     2.328380\n",
       "1            AE    Assembly       2     2.075547\n",
       "2            AE    Assembly       3     2.498311\n",
       "3            AE    Assembly       4     2.240549\n",
       "4            AE   Batchfile       1     2.748963\n",
       "...         ...         ...     ...          ...\n",
       "25357        ZW       Shell       4     2.501059\n",
       "25358        ZW  TypeScript       1     2.326336\n",
       "25359        ZW  TypeScript       2     2.481443\n",
       "25360        ZW  TypeScript       3     2.522444\n",
       "25361        ZW  TypeScript       4     2.285557\n",
       "\n",
       "[25362 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = df.groupby([\"iso2_code\", \"language\", \"period\"])[\"num_pushers\"]\\\n",
    "    .agg(\"sum\")\\\n",
    "    .reset_index()\n",
    "\n",
    "if log_num_pushers == True:\n",
    "    dfs[\"num_pushers\"] = np.log10(dfs[\"num_pushers\"])\n",
    "#dfb1 = bundle_data(df, periods=[1,2])\n",
    "#dfb2 = bundle_data(df, periods=[3,4])\n",
    "#dfb2[\"period\"] = 2\n",
    "#dfbs = pd.concat([dfb1, dfb2])\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "4\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/gf/x21_n30n2l13jz3jhcfzjc_40000gn/T/ipykernel_34326/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfs[\"period\"].unique():\n",
    "    print(p)\n",
    "    rca_df = dfs[dfs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\"))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the entry style\n",
    "pattern = [0,0,1]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "cdf = pd.read_csv(\"../outputs/software_complexity_2020_2021_based_log.csv\", sep=\";\")\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "# cdf = pd.read_csv(\"../outputs/complexity_table2020.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==1].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "software_space_el = pd.read_csv(\"../outputs/software_space_2020_2021_based_log.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el,\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "full_df.to_csv(\"../outputs/data_entry_regression_version3_semester_based_log.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42619, 9)\n"
     ]
    }
   ],
   "source": [
    "# version 2 -- quarter panel\n",
    "selected_period = \"semester\"\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = df[df[\"year\"]>2021]\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
