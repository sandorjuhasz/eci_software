{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib import cm, colors\n",
    "\n",
    "from ecomplexity import ecomplexity\n",
    "from ecomplexity import proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "window = [2020, 2021]\n",
    "export_cdf_yearly = False\n",
    "export_cdf_window = True\n",
    "\n",
    "# for ecomplexity calculcation\n",
    "key_cols = {\n",
    "    \"time\": \"year\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"language\",\n",
    "    \"val\": \"num_pushers\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - git complexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../data/languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter functions\n",
    "def drop_specifics_from_list(data, filter_list):\n",
    "    \"\"\"filter specific languages from list -- motivated by RM del Rio-Chanona et al 2023\"\"\"\n",
    "    data = data[~data[\"language\"].str.contains(filter_list, case=False, regex=True)]\n",
    "    return data\n",
    "\n",
    "def top_languages_filter(data, nr_languages):\n",
    "    \"\"\"keep top x number of languages ONLY\"\"\"\n",
    "    top_languages = data.groupby([\"language\"])[\"num_pushers\"].agg(\"sum\").reset_index().sort_values(by=\"num_pushers\", ascending=False)\n",
    "    top_languages = list(top_languages[\"language\"])[:nr_languages]\n",
    "    data = data[data[\"language\"].isin(top_languages)]\n",
    "    return data\n",
    "    \n",
    "def drop_country_codes_from_list(data, country_list):\n",
    "    data = data[~data[\"iso2_code\"].isin(country_list)]\n",
    "    return data\n",
    "\n",
    "def dataframe_for_ecomplexity(data, focal_year, quarter_list):\n",
    "    \"\"\"aggregate and transform dataframe for ecomplexity functions\"\"\"\n",
    "    data = data[(data[\"year\"]==focal_year) & (data[\"quarter\"].isin(quarter_list))]\n",
    "    data = data\\\n",
    "        .groupby([\"year\", \"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\\\n",
    "        .sort_values(by=\"num_pushers\", ascending=False)    \n",
    "    return data\n",
    "    \n",
    "def add_period_ids(data):\n",
    "    \"\"\"create missing semester ID and construct different period IDs\"\"\"\n",
    "    data[\"semester\"] = np.where(data[\"quarter\"] <= 2, 1, 2)\n",
    "    data[\"semester_id\"] = data[\"year\"].astype(str).str.cat(data[\"semester\"].astype(str), sep=\"s\")\n",
    "    data[\"quarter_id\"] = data[\"year\"].astype(str).str.cat(data[\"quarter\"].astype(str), sep=\"q\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74289, 9)\n"
     ]
    }
   ],
   "source": [
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n",
      "2021\n",
      "2022\n",
      "2023\n"
     ]
    }
   ],
   "source": [
    "# loop to calculate ecomplexity for each year\n",
    "years = sorted(df[\"year\"].unique())\n",
    "for y in years:\n",
    "    df_prep = dataframe_for_ecomplexity(df, focal_year=y, quarter_list=[1, 2, 3, 4])\n",
    "    cdf = ecomplexity(df_prep, key_cols)\n",
    "    \n",
    "    if export_cdf_yearly==True:\n",
    "        cdf.to_csv(f\"../outputs/complexity_table{y}.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_7355/2845567388.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  window_data[\"year\"] = window[0]\n"
     ]
    }
   ],
   "source": [
    "# window information\n",
    "window_data = df[df[\"year\"].isin(window)]  \n",
    "window_id = '-'.join(map(str, window))\n",
    "window_data[\"year\"] = window[0]\n",
    "\n",
    "# ecomplexity for window\n",
    "df_wprep = dataframe_for_ecomplexity(window_data, focal_year=window[0], quarter_list=[1, 2, 3, 4])\n",
    "cdf_w = ecomplexity(df_wprep, key_cols)\n",
    "cdf_w[\"window\"] = window_id\n",
    "if export_cdf_window==True:\n",
    "    cdf_w.to_csv(f\"../outputs/complexity_table{window_id}.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2 - language space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    }
   ],
   "source": [
    "# github space\n",
    "space_df = proximity(df_wprep, key_cols)\n",
    "# space_df.to_csv(\"../outputs/space_table.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgelist_for_github_space(data, key_columns):\n",
    "    \"\"\"transform the ecomplexity proximity output for visualization\"\"\"\n",
    "    data = data[key_columns]\n",
    "\n",
    "    # drop zero -- non-existing edges\n",
    "    data = data[data[key_columns[2]] > 0]\n",
    "\n",
    "    # drop self loops\n",
    "    data = data[data[key_columns[0]] != data[key_columns[1]]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_spanning_tree(data, key_columns):\n",
    "    table = data.copy()\n",
    "    table[\"distance\"] = 1.0 / table[key_columns[2]]\n",
    "    G = nx.from_pandas_edgelist(table, source = key_columns[0], target = key_columns[1], edge_attr = [\"distance\", key_columns[2]])\n",
    "    T = nx.minimum_spanning_tree(G, weight = \"distance\")\n",
    "    table2 = nx.to_pandas_edgelist(T)\n",
    "    table2 = table2[table2[key_columns[2]] > 0]\n",
    "    table2.rename(columns = {\"source\": key_columns[0], \"target\": key_columns[1], key_columns[2]: \"score\"}, inplace = True)\n",
    "    table = pd.merge(\n",
    "        table,\n",
    "        table2,\n",
    "        on=key_columns[0:2]\n",
    "    )  \n",
    "    table[\"edge\"] = table.apply(lambda x: \"%s-%s\" % (min(x[key_columns[0]], x[key_columns[1]]), max(x[key_columns[0]], x[key_columns[1]])), axis = 1)\n",
    "    table = table.drop_duplicates(subset = [\"edge\"])\n",
    "    table = table.drop(\"edge\", 1)\n",
    "    return table[key_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges(mst_edges, all_edges, nr_edges_to_add):\n",
    "    # drop mst edges from the full edgelist\n",
    "    mst_edges[\"drop\"] = 1\n",
    "    all_edges = pd.merge(\n",
    "        all_edges,\n",
    "        mst_edges,\n",
    "        on = [\"language_1\", \"language_2\", \"proximity\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    all_edges = all_edges[all_edges[\"drop\"] != 1].drop(columns=\"drop\")\n",
    "\n",
    "    # sort and select\n",
    "    all_edges = all_edges.sort_values(by=\"proximity\", ascending=False).iloc[:nr_edges_to_add]\n",
    "\n",
    "    # add to mst edgelist\n",
    "    software_space_el = pd.concat([mst_el, all_edges])\n",
    "    return software_space_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_7355/2237830232.py:16: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  table = table.drop(\"edge\", 1)\n"
     ]
    }
   ],
   "source": [
    "# from space table to MST w/ additional edges\n",
    "space_table = edgelist_for_github_space(space_df, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_el = maximum_spanning_tree(space_table, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_graph = nx.from_pandas_edgelist(mst_el, source=\"language_1\", target=\"language_2\")\n",
    "n_nodes = mst_graph.number_of_nodes()\n",
    "n_edges = n_nodes * 2\n",
    "software_space_el = add_edges(mst_el, space_table, nr_edges_to_add=n_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for Herr Wachs\n",
    "software_space_el.to_csv(f\"../outputs/software_space_edgelist{window_id}.csv\", index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
