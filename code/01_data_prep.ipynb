{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from ecomplexity import ecomplexity\n",
    "from ecomplexity import proximity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 0 - general data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "selected_period = \"year\"\n",
    "#period_for_complexity = 1\n",
    "log_num_pushers = False\n",
    "\n",
    "# for ecomplexity calculcation\n",
    "key_cols = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"language\",\n",
    "    \"val\": \"num_pushers\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../data/languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter functions\n",
    "def drop_specifics_from_list(data, filter_list):\n",
    "    \"\"\"filter specific languages from list -- motivated by RM del Rio-Chanona et al 2023\"\"\"\n",
    "    data = data[~data[\"language\"].str.contains(filter_list, case=False, regex=True)]\n",
    "    return data\n",
    "\n",
    "def top_languages_filter(data, nr_languages):\n",
    "    \"\"\"keep top x number of languages ONLY\"\"\"\n",
    "    top_languages = data.groupby([\"language\"])[\"num_pushers\"].agg(\"sum\").reset_index().sort_values(by=\"num_pushers\", ascending=False)\n",
    "    top_languages = list(top_languages[\"language\"])[:nr_languages]\n",
    "    data = data[data[\"language\"].isin(top_languages)]\n",
    "    return data\n",
    "    \n",
    "def drop_country_codes_from_list(data, country_list):\n",
    "    data = data[~data[\"iso2_code\"].isin(country_list)]\n",
    "    data = data.dropna(subset=\"iso2_code\")\n",
    "    return data\n",
    "\n",
    "def add_period_ids(data, period):\n",
    "    \"\"\"create missing semester ID and construct different period IDs\"\"\"\n",
    "    if period==\"year\":\n",
    "        year_to_period = dict(zip(data[\"year\"].unique(), list(range(1, len(data[\"year\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"year\"].map(year_to_period)\n",
    "    if period==\"semester\":\n",
    "        data[\"semester\"] = np.where(data[\"quarter\"] <= 2, 1, 2)\n",
    "        data[\"semester_id\"] = data[\"year\"].astype(str).str.cat(data[\"semester\"].astype(str), sep=\"s\")\n",
    "        semester_to_period = dict(zip(data[\"semester_id\"].unique(), list(range(1, len(data[\"semester_id\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"semester_id\"].map(semester_to_period)\n",
    "    if period==\"quarter\":\n",
    "        data[\"quarter_id\"] = data[\"year\"].astype(str).str.cat(data[\"quarter\"].astype(str), sep=\"q\")\n",
    "        quarter_to_period = dict(zip(data[\"quarter_id\"].unique(), list(range(1, len(data[\"quarter_id\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"quarter_id\"].map(quarter_to_period)\n",
    "    return data\n",
    "\n",
    "\n",
    "# probably we can delete later\n",
    "def dataframe_for_ecomplexity(data, period):\n",
    "    \"\"\"aggregate and transform dataframe for ecomplexity functions\"\"\"\n",
    "    #data = data[(data[\"year\"]==focal_year) & (data[\"quarter\"].isin(quarter_list))]\n",
    "    data = data[(data[\"period\"]==period)]\n",
    "    data = data\\\n",
    "        .groupby([\"period\", \"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\\\n",
    "        .sort_values(by=\"num_pushers\", ascending=False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84934, 7)\n"
     ]
    }
   ],
   "source": [
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the log of num_pushers\n",
    "if log_num_pushers == True:\n",
    "    df[\"num_pushers\"] = np.log10(df[\"num_pushers\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 - M_{cl} - relatedness - complexity - 2020-2021**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle data for M_{cl}\n",
    "def bundle_data(data, periods):\n",
    "    data = data[data[\"period\"].isin(periods)]\\\n",
    "        .groupby([\"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\n",
    "    data[\"period\"] = 1\n",
    "    return data\n",
    "\n",
    "dfb = bundle_data(df, periods=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# software complexity calculation\n",
    "cdf = ecomplexity(dfb, key_cols)\n",
    "cdf.to_csv(\"../outputs/software_complexity_2020_2021_based.csv\", index=False, sep=\";\")\n",
    "\n",
    "# github space\n",
    "space_df = proximity(dfb, key_cols)\n",
    "space_df.to_csv(\"../outputs/software_space_2020_2021_based.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf.drop_duplicates(subset=\"language\").sort_values(by=\"pci\").tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get relatedness network from raw proximity values\n",
    "\n",
    "def edgelist_for_github_space(data, key_columns):\n",
    "    \"\"\"transform the ecomplexity proximity output for visualization\"\"\"\n",
    "    data = data[key_columns]\n",
    "\n",
    "    # drop zero -- non-existing edges\n",
    "    data = data[data[key_columns[2]] > 0]\n",
    "\n",
    "    # drop self loops\n",
    "    data = data[data[key_columns[0]] != data[key_columns[1]]]\n",
    "    return data\n",
    "\n",
    "def maximum_spanning_tree(data, key_columns):\n",
    "    table = data.copy()\n",
    "    table[\"distance\"] = 1.0 / table[key_columns[2]]\n",
    "    G = nx.from_pandas_edgelist(table, source = key_columns[0], target = key_columns[1], edge_attr = [\"distance\", key_columns[2]])\n",
    "    T = nx.minimum_spanning_tree(G, weight = \"distance\")\n",
    "    table2 = nx.to_pandas_edgelist(T)\n",
    "    table2 = table2[table2[key_columns[2]] > 0]\n",
    "    table2.rename(columns = {\"source\": key_columns[0], \"target\": key_columns[1], key_columns[2]: \"score\"}, inplace = True)\n",
    "    table = pd.merge(\n",
    "        table,\n",
    "        table2,\n",
    "        on=key_columns[0:2]\n",
    "    )  \n",
    "    table[\"edge\"] = table.apply(lambda x: \"%s-%s\" % (min(x[key_columns[0]], x[key_columns[1]]), max(x[key_columns[0]], x[key_columns[1]])), axis = 1)\n",
    "    table = table.drop_duplicates(subset = [\"edge\"])\n",
    "    table = table.drop(\"edge\", 1)\n",
    "    return table[key_columns]\n",
    "\n",
    "def add_edges(mst_edges, all_edges, nr_edges_to_add):\n",
    "    # drop mst edges from the full edgelist\n",
    "    mst_edges[\"drop\"] = 1\n",
    "    all_edges = pd.merge(\n",
    "        all_edges,\n",
    "        mst_edges,\n",
    "        on = [\"language_1\", \"language_2\", \"proximity\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    all_edges = all_edges[all_edges[\"drop\"] != 1].drop(columns=\"drop\")\n",
    "\n",
    "    # sort and select\n",
    "    all_edges = all_edges.sort_values(by=\"proximity\", ascending=False).iloc[:nr_edges_to_add]\n",
    "\n",
    "    # add to mst edgelist\n",
    "    software_space_el = pd.concat([mst_el, all_edges])\n",
    "    return software_space_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# from space table to MST w/ additional edges\u001b[39;00m\n\u001b[1;32m      2\u001b[0m space_table \u001b[38;5;241m=\u001b[39m edgelist_for_github_space(space_df, key_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproximity\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m mst_el \u001b[38;5;241m=\u001b[39m \u001b[43mmaximum_spanning_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspace_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlanguage_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mproximity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m mst_graph \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mfrom_pandas_edgelist(mst_el, source\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m n_nodes \u001b[38;5;241m=\u001b[39m mst_graph\u001b[38;5;241m.\u001b[39mnumber_of_nodes()\n",
      "Cell \u001b[0;32mIn[10], line 29\u001b[0m, in \u001b[0;36mmaximum_spanning_tree\u001b[0;34m(data, key_columns)\u001b[0m\n\u001b[1;32m     27\u001b[0m table[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mmin\u001b[39m(x[key_columns[\u001b[38;5;241m0\u001b[39m]], x[key_columns[\u001b[38;5;241m1\u001b[39m]]), \u001b[38;5;28mmax\u001b[39m(x[key_columns[\u001b[38;5;241m0\u001b[39m]], x[key_columns[\u001b[38;5;241m1\u001b[39m]])), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medge\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 29\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medge\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table[key_columns]\n",
      "\u001b[0;31mTypeError\u001b[0m: DataFrame.drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "# from space table to MST w/ additional edges\n",
    "space_table = edgelist_for_github_space(space_df, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_el = maximum_spanning_tree(space_table, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_graph = nx.from_pandas_edgelist(mst_el, source=\"language_1\", target=\"language_2\")\n",
    "n_nodes = mst_graph.number_of_nodes()\n",
    "n_edges = n_nodes * 2\n",
    "software_space_el = add_edges(mst_el, space_table, nr_edges_to_add=n_edges)\n",
    "\n",
    "# export for Herr Wachs\n",
    "software_space_el.to_csv(\"../outputs/software_space_edgelist_2020_2021_based.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 - regression data for cross-sectional entry models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2 -- (2022) -- entry in (2023)\n",
    "\n",
    "# bundle data for M_{cl}\n",
    "dfb3 = bundle_data(df, periods=[3])\n",
    "dfb4 = bundle_data(df, periods=[4])\n",
    "dfb3[\"period\"] = 3\n",
    "dfb4[\"period\"] = 4\n",
    "dfbs = pd.concat([dfb3, dfb4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rca_calculation(table, c_column, p_column, value_column):\n",
    "    \"\"\"calculate RCA from an M_cp dataframe\"\"\"\n",
    "    table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
    "    table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
    "    table[\"e\"] = table[value_column].sum()\n",
    "\n",
    "    table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
    "    table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfbs[\"period\"].unique():\n",
    "    rca_df = dfbs[dfbs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\"))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the entry style\n",
    "entry_pattern = [0,1]\n",
    "consider_pattern = [0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "# cdf = pd.read_csv(\"../outputs/complexity_table2020.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/2441075573.py:6: FutureWarning: The provided callable <function sum at 0x11aac19e0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  relatedness = pd.pivot_table(\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/2441075573.py:18: FutureWarning: The provided callable <function sum at 0x11aac19e0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  mat = pd.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "#software_space_el = pd.read_csv(\"../outputs/software_space_edgelist2020.csv\", sep=\";\")\n",
    "software_space_el = pd.read_csv(\"../outputs/software_space_edgelist.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el,\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_entry_regression_2022_to_2023.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso2_code</th>\n",
       "      <th>language</th>\n",
       "      <th>entry01</th>\n",
       "      <th>consider00</th>\n",
       "      <th>pci</th>\n",
       "      <th>rca01</th>\n",
       "      <th>rel_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AE</td>\n",
       "      <td>Assembly</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.930404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AE</td>\n",
       "      <td>Batchfile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.600481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AE</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.473052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AE</td>\n",
       "      <td>C#</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AE</td>\n",
       "      <td>C++</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.367525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21900</th>\n",
       "      <td>ZA</td>\n",
       "      <td>XSLT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.055318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21918</th>\n",
       "      <td>ZM</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.473052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21988</th>\n",
       "      <td>ZM</td>\n",
       "      <td>PHP</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.713058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22081</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Dockerfile</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.199149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.847196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2648 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iso2_code          language  entry01  consider00       pci  rca01  \\\n",
       "8            AE          Assembly        0           1  1.930404    0.0   \n",
       "11           AE         Batchfile        0           1  1.600481    0.0   \n",
       "15           AE                 C        1           0  1.473052    0.0   \n",
       "16           AE                C#        0           1  0.109249    0.0   \n",
       "17           AE               C++        0           1  1.367525    0.0   \n",
       "...         ...               ...      ...         ...       ...    ...   \n",
       "21900        ZA              XSLT        0           1  2.055318    0.0   \n",
       "21918        ZM                 C        1           0  1.473052    0.0   \n",
       "21988        ZM               PHP        1           0 -0.713058    0.0   \n",
       "22081        ZW        Dockerfile        0           1  1.199149    0.0   \n",
       "22111        ZW  Jupyter Notebook        1           0  0.847196    0.0   \n",
       "\n",
       "       rel_density  \n",
       "8         0.000000  \n",
       "11        0.500000  \n",
       "15        0.333333  \n",
       "16        1.000000  \n",
       "17        0.000000  \n",
       "...            ...  \n",
       "21900     0.000000  \n",
       "21918     0.000000  \n",
       "21988     1.000000  \n",
       "22081     0.666667  \n",
       "22111     0.000000  \n",
       "\n",
       "[2648 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**outdated versions -- will delete later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 -- (2020-2021) -- entry in (2022-2023)\n",
    "\n",
    "# bundle data for M_{cl}\n",
    "def bundle_data(data, periods):\n",
    "    data = data[data[\"period\"].isin(periods)]\\\n",
    "        .groupby([\"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\n",
    "    data[\"period\"] = 1\n",
    "    return data\n",
    "\n",
    "dfb1 = bundle_data(df, periods=[1,2])\n",
    "dfb2 = bundle_data(df, periods=[3,4])\n",
    "dfb2[\"period\"] = 2\n",
    "dfbs = pd.concat([dfb1, dfb2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rca_calculation(table, c_column, p_column, value_column):\n",
    "    \"\"\"calculate RCA from an M_cp dataframe\"\"\"\n",
    "    table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
    "    table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
    "    table[\"e\"] = table[value_column].sum()\n",
    "\n",
    "    table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
    "    table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfbs[\"period\"].unique():\n",
    "    rca_df = dfbs[dfbs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\"))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the entry style\n",
    "pattern = [0,1]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "# cdf = pd.read_csv(\"../outputs/complexity_table2020.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==1].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/1782568363.py:5: FutureWarning: The provided callable <function sum at 0x11aac19e0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  relatedness = pd.pivot_table(\n",
      "/var/folders/2p/6l40fg513x76rr7vpl0f6_6m0000gn/T/ipykernel_72156/1782568363.py:17: FutureWarning: The provided callable <function sum at 0x11aac19e0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  mat = pd.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "#software_space_el = pd.read_csv(\"../outputs/software_space_edgelist2020.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el,\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==1].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "#full_df.to_csv(\"../outputs/data_entry_regression_version1_2023q_added.csv\", index=False, sep=\";\")\n",
    "full_df.to_csv(\"../outputs/data_entry_regression_version1_log.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'consider00'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/github-complexity/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'consider00'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# export for entry models\u001b[39;00m\n\u001b[1;32m      2\u001b[0m full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry01\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry01\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsider00\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfull_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconsider00\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      4\u001b[0m export_df \u001b[38;5;241m=\u001b[39m full_df[(full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mentry01\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m|\u001b[39m (full_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsider00\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m      5\u001b[0m export_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../outputs/data_entry_regression_version3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/github-complexity/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.virtualenvs/github-complexity/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'consider00'"
     ]
    }
   ],
   "source": [
    "# export for entry models\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_entry_regression_version3.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "\n",
    "#full_df.to_csv(\"../outputs/data_entry_regression_version2_2023q_added.csv\", index=False, sep=\";\")\n",
    "#full_df.to_csv(\"../outputs/data_entry_regression_version2_log.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 - panel data for entry regressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 -- semester -- actually a cross-section ...\n",
    "# version 2 -- quarter panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 1 -- semester panel\n",
    "selected_period = \"semester\"\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = df[df[\"year\"]>2021]\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = df.groupby([\"iso2_code\", \"language\", \"period\"])[\"num_pushers\"]\\\n",
    "    .agg(\"sum\")\\\n",
    "    .reset_index()\n",
    "\n",
    "if log_num_pushers == True:\n",
    "    dfs[\"num_pushers\"] = np.log10(dfs[\"num_pushers\"])\n",
    "#dfb1 = bundle_data(df, periods=[1,2])\n",
    "#dfb2 = bundle_data(df, periods=[3,4])\n",
    "#dfb2[\"period\"] = 2\n",
    "#dfbs = pd.concat([dfb1, dfb2])\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfs[\"period\"].unique():\n",
    "    print(p)\n",
    "    rca_df = dfs[dfs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\"))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the entry style\n",
    "pattern = [0,0,1]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "cdf = pd.read_csv(\"../outputs/software_complexity_2020_2021_based_log.csv\", sep=\";\")\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "# cdf = pd.read_csv(\"../outputs/complexity_table2020.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==1].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#software_space_el = pd.read_csv(\"../outputs/software_space_2020_2021_based_log.csv\", sep=\";\")\n",
    "software_space_el = pd.read_csv(\"../outputs/software_space_edgelist.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el,\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models\n",
    "full_df.to_csv(\"../outputs/data_entry_regression_version3_semester_based_log.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2 -- quarter panel\n",
    "selected_period = \"semester\"\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = df[df[\"year\"]>2021]\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
