{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from ecomplexity import ecomplexity\n",
    "from ecomplexity import proximity\n",
    "from ecomplexity import calc_density\n",
    "import country_converter as coco\n",
    "import itertools\n",
    "\n",
    "# spatial autocorrelation\n",
    "import geopandas as gpd\n",
    "from pysal.lib import weights\n",
    "from libpysal.io import open as psopen\n",
    "from splot.esda import (\n",
    "    moran_scatterplot, lisa_cluster, plot_local_autocorrelation, plot_moran\n",
    ")\n",
    "from splot.libpysal import plot_spatial_weights\n",
    "import esda\n",
    "\n",
    "import yaml\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.config_utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "config = load_config()\n",
    "focal_year = config[\"focal_year\"]\n",
    "selected_period = config[\"selected_period\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**different RCA thresholds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved in data prep\n",
    "eci_software = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_26257/1169018816.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eci_df[\"mcp075\"] = np.where(eci_df[\"rca\"]>=0.75, 1, 0)\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_26257/1169018816.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  eci_df[\"mcp125\"] = np.where(eci_df[\"rca\"]>=1.25, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# year focus\n",
    "eci_df = eci_software[eci_software[\"year\"]==2020]\n",
    "eci_df[\"mcp075\"] = np.where(eci_df[\"rca\"]>=0.75, 1, 0)\n",
    "eci_df[\"mcp125\"] = np.where(eci_df[\"rca\"]>=1.25, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcp_crosstable(df, columns):\n",
    "    mcp_crosstable = df[columns].value_counts().reset_index().sort_values(by=columns).rename(columns={\"count\":\"obs\"})\n",
    "    mcp_crosstable[\"obs_share\"] = round(mcp_crosstable[\"obs\"] / mcp_crosstable[\"obs\"].sum(), 2)\n",
    "    return mcp_crosstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcp</th>\n",
       "      <th>mcp075</th>\n",
       "      <th>obs</th>\n",
       "      <th>obs_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5876</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1914</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcp  mcp075   obs  obs_share\n",
       "0    0       0  5876       0.70\n",
       "2    0       1   589       0.07\n",
       "1    1       1  1914       0.23"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcp_crosstable(eci_df, columns=[\"mcp\", \"mcp075\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mcp</th>\n",
       "      <th>mcp125</th>\n",
       "      <th>obs</th>\n",
       "      <th>obs_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6465</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1318</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mcp  mcp125   obs  obs_share\n",
       "0    0       0  6465       0.77\n",
       "2    1       0   596       0.07\n",
       "1    1       1  1318       0.16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcp_crosstable(eci_df, columns=[\"mcp\", \"mcp125\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93076, 7)\n"
     ]
    }
   ],
   "source": [
    "# data IN -- for threshold 0.75 AND 1.25\n",
    "\n",
    "# data IN\n",
    "data = pd.read_csv(\"../../data/inputs/languages.csv\")\n",
    "\n",
    "# use data_prep_functions to clean the dataframe of ECI_software calculation\n",
    "data = data[data[\"year\"].isin([2020, 2021, 2022, 2023])]\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "1\n",
      "Percentage of pairs compared that meet log-supermodularity condition: 6.16%\n",
      "1\n",
      "2020  DONE\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 1: Log-supermodularity condition is not fully satisfied (6.16% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 6.64%\n",
      "2\n",
      "2021  DONE\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 2: Log-supermodularity condition is not fully satisfied (6.64% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 7.07%\n",
      "3\n",
      "2022  DONE\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 3: Log-supermodularity condition is not fully satisfied (7.07% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 7.68%\n",
      "4\n",
      "2023  DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 4: Log-supermodularity condition is not fully satisfied (7.68% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25\n",
      "1\n",
      "Percentage of pairs compared that meet log-supermodularity condition: 6.72%\n",
      "1\n",
      "2020  DONE\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 1: Log-supermodularity condition is not fully satisfied (6.72% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 7.64%\n",
      "2\n",
      "2021  DONE\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 2: Log-supermodularity condition is not fully satisfied (7.64% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 8.27%\n",
      "3\n",
      "2022  DONE\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 3: Log-supermodularity condition is not fully satisfied (8.27% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 9.98%\n",
      "4\n",
      "2023  DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 4: Log-supermodularity condition is not fully satisfied (9.98% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# clusters of languages\n",
    "cl_df = pd.read_csv(\"../../data/outputs/language_clusters_gh_cos_hier_ward_d1.csv\")\\\n",
    "    .rename(columns={\"Language\":\"language\", \"Cluster\":\"cluster_id\"})\\\n",
    "    .iloc[:,1:]\n",
    "\n",
    "# combine\n",
    "cl_df = pd.merge(\n",
    "    df,\n",
    "    cl_df,\n",
    "    on=\"language\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# drop NAs... -- not so great\n",
    "cl_df.dropna(subset=[\"cluster_id\", \"cluster_id\"], inplace=True)\n",
    "\n",
    "# aggregate by clusters\n",
    "cl_df = cl_df.groupby([\"iso2_code\", \"period\", \"cluster_id\"])[\"num_pushers\"].agg(\"mean\").reset_index()\n",
    "\n",
    "# for ecomplexity calculcation\n",
    "key_cols = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"cluster_id\",\n",
    "    \"val\": \"num_pushers\",\n",
    "}\n",
    "\n",
    "# software complexity calculation -- period IDs -- 1 means 2020 on yearly basis\n",
    "thresholds = [0.75, 1.25]\n",
    "for t in thresholds:\n",
    "    print(t)\n",
    "    ccdf = []\n",
    "    ppdf = []\n",
    "    year_dict = {1 : 2020, 2 : 2021, 3 : 2022, 4 : 2023}\n",
    "    for k in year_dict.keys():\n",
    "        dfb = cl_df[cl_df[\"period\"]==k]\n",
    "        cdf = ecomplexity(dfb, key_cols, rca_mcp_threshold=t)\n",
    "        cdf[\"year\"] = year_dict[k]\n",
    "\n",
    "        pdf = proximity(dfb, key_cols, rca_mcp_threshold=t)\n",
    "        pdf[\"year\"] = year_dict[k]\n",
    "\n",
    "        # combine yearly dataframes\n",
    "        ccdf.append(cdf)\n",
    "        ppdf.append(pdf)\n",
    "        print(year_dict[k], \" DONE\")\n",
    "\n",
    "        # combine and save -- complexity\n",
    "        cdf = pd.concat(ccdf, axis=0, ignore_index=True)\n",
    "        cdf.to_csv(f\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_{int(t*100)}.csv\", sep=\";\", index=False)\n",
    "\n",
    "        # combine and save -- language proximity\n",
    "        prox_df = pd.concat(ppdf, axis=0, ignore_index=True)\n",
    "        prox_df.to_csv(f\"../../data/outputs/proximity_clusters_2020_2023_threshold_{int(t*100)}.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eci100</th>\n",
       "      <th>eci075</th>\n",
       "      <th>eci125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eci100</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978869</td>\n",
       "      <td>0.903184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci075</th>\n",
       "      <td>0.978869</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci125</th>\n",
       "      <td>0.903184</td>\n",
       "      <td>0.881004</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          eci100    eci075    eci125\n",
       "eci100  1.000000  0.978869  0.903184\n",
       "eci075  0.978869  1.000000  0.881004\n",
       "eci125  0.903184  0.881004  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation matrix\n",
    "cdf100 = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023.csv\", sep=\";\")\n",
    "cdf100 = cdf100[cdf100[\"year\"]==2020]\n",
    "cdf075 = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_75.csv\", sep=\";\")\n",
    "cdf075 = cdf075[cdf075[\"year\"]==2020]\n",
    "cdf125 = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_125.csv\", sep=\";\")\n",
    "cdf125 = cdf125[cdf125[\"year\"]==2020].rename(columns={\"eci\":\"eci125\"})\n",
    "\n",
    "full_cdf = pd.merge(\n",
    "    cdf100[[\"iso2_code\", \"eci\"]].drop_duplicates(),\n",
    "    cdf075[[\"iso2_code\", \"eci\"]].drop_duplicates(),\n",
    "    on=[\"iso2_code\"],\n",
    "    how=\"left\",\n",
    "    suffixes=[\"100\", \"075\"]\n",
    ")\n",
    "full_cdf = pd.merge(\n",
    "    full_cdf,\n",
    "    cdf125,\n",
    "    on=[\"iso2_code\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# correlation matri -- ECI across thresholds\n",
    "full_cdf[[\"eci100\", \"eci075\", \"eci125\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### ENTRY -- 0.75 threshold\n",
    "\n",
    "# relatedness density -- as in Hidalgo et al. (2007) Science\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_75.csv\", sep=\";\")\n",
    "rel_dens = cdf[cdf[\"year\"] == 2020][[\"iso2_code\", \"cluster_id\", \"density\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "# data IN\n",
    "# use cl_df from the previous section\n",
    "\n",
    "# threshold for RCA : 0.75\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data(cl_df, periods=[p], key_column=\"cluster_id\")\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"cluster_id\", value_column=\"num_pushers\", threshold=0.75))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)\n",
    "\n",
    "\n",
    "\n",
    "# identify entry following the given patterns\n",
    "entry_pattern = [0,0,1,1]\n",
    "consider_pattern = [0,0,0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"cluster_id\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_clusters = ent[\"cluster_id\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_clusters))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"cluster_id\"])\\\n",
    "    .sort_values([\"iso2_code\", \"cluster_id\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"cluster_id\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_75.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"cluster_id\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"cluster_id\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rel_dens,\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../../data/outputs/data_cluster_entry_regressions_0011_threshold_075.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### ENTRY -- 1.25 threshold\n",
    "\n",
    "# relatedness density -- as in Hidalgo et al. (2007) Science\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_125.csv\", sep=\";\")\n",
    "rel_dens = cdf[cdf[\"year\"] == 2020][[\"iso2_code\", \"cluster_id\", \"density\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "# data IN\n",
    "# use cl_df from the previous section\n",
    "\n",
    "# threshold for RCA : 1.25\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data(cl_df, periods=[p], key_column=\"cluster_id\")\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"cluster_id\", value_column=\"num_pushers\", threshold=1.25))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)\n",
    "\n",
    "\n",
    "\n",
    "# identify entry following the given patterns\n",
    "entry_pattern = [0,0,1,1]\n",
    "consider_pattern = [0,0,0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"cluster_id\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_clusters = ent[\"cluster_id\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_clusters))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"cluster_id\"])\\\n",
    "    .sort_values([\"iso2_code\", \"cluster_id\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"cluster_id\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_125.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"cluster_id\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"cluster_id\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rel_dens,\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../../data/outputs/data_cluster_entry_regressions_0011_threshold_125.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### EXIT -- 0.75 threshold\n",
    "\n",
    "# relatedness density -- as in Hidalgo et al. (2007) Science\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_75.csv\", sep=\";\")\n",
    "rel_dens = cdf[cdf[\"year\"] == 2020][[\"iso2_code\", \"cluster_id\", \"density\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "# data IN\n",
    "# use cl_df from the previous section\n",
    "\n",
    "\n",
    "# threshold for RCA : 0.75\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data(cl_df, periods=[p], key_column=\"cluster_id\")\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"cluster_id\", value_column=\"num_pushers\", threshold=0.75))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)\n",
    "\n",
    "\n",
    "\n",
    "# identify entry following the given patterns\n",
    "exit_pattern = [1,1,0,0]\n",
    "consider_pattern = [1,1,1,1]\n",
    "ext = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"cluster_id\"])[\"rca01\"].agg(list).reset_index()\n",
    "ext[\"entry01\"] = ext[\"rca01\"].apply(lambda x: x == exit_pattern).astype(int)\n",
    "ext[\"consider00\"] = ext[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# full combination\n",
    "all_countries = ext[\"iso2_code\"].unique()\n",
    "all_clusters = ext[\"cluster_id\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_clusters))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"cluster_id\"])\\\n",
    "    .sort_values([\"iso2_code\", \"cluster_id\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ext[[\"iso2_code\", \"cluster_id\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_75.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"cluster_id\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"cluster_id\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rel_dens,\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df.rename(columns={\"entry01\":\"exit01\"}, inplace=True)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"exit01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../../data/outputs/data_cluster_exit_regressions_1100_threshold_075.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### EXIT -- 1.25 threshold\n",
    "\n",
    "# relatedness density -- as in Hidalgo et al. (2007) Science\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_125.csv\", sep=\";\")\n",
    "rel_dens = cdf[cdf[\"year\"] == 2020][[\"iso2_code\", \"cluster_id\", \"density\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "# data IN\n",
    "# use cl_df from the previous section\n",
    "\n",
    "\n",
    "# threshold for RCA : 1.25\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data(cl_df, periods=[p], key_column=\"cluster_id\")\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"cluster_id\", value_column=\"num_pushers\", threshold=0.75))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)\n",
    "\n",
    "\n",
    "\n",
    "# identify entry following the given patterns\n",
    "exit_pattern = [1,1,0,0]\n",
    "consider_pattern = [1,1,1,1]\n",
    "ext = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"cluster_id\"])[\"rca01\"].agg(list).reset_index()\n",
    "ext[\"entry01\"] = ext[\"rca01\"].apply(lambda x: x == exit_pattern).astype(int)\n",
    "ext[\"consider00\"] = ext[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# full combination\n",
    "all_countries = ext[\"iso2_code\"].unique()\n",
    "all_clusters = ext[\"cluster_id\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_clusters))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"cluster_id\"])\\\n",
    "    .sort_values([\"iso2_code\", \"cluster_id\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ext[[\"iso2_code\", \"cluster_id\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023_threshold_125.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"cluster_id\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"cluster_id\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rel_dens,\n",
    "    on=[\"iso2_code\", \"cluster_id\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df.rename(columns={\"entry01\":\"exit01\"}, inplace=True)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"exit01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../../data/outputs/data_cluster_exit_regressions_1100_threshold_125.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spatial autocorrelation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data -- ECI_software\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "cdf = cdf[[\"iso2_code\", \"eci\"]].drop_duplicates()\n",
    "\n",
    "# data -- world map\n",
    "cmap = gpd.read_file(\"../../data/inputs/world-administrative-boundaries.geojson\")\n",
    "cmap = cmap[[\"iso3\", \"iso_3166_1_alpha_2_codes\", \"name\", \"geometry\"]].rename(columns={\"iso_3166_1_alpha_2_codes\" : \"iso2\"})\n",
    "\n",
    "cmap = pd.merge(\n",
    "    cmap,\n",
    "    cdf,\n",
    "    left_on=\"iso2\",\n",
    "    right_on=\"iso2_code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# clean up\n",
    "cmap = cmap.drop_duplicates(subset=[\"iso2\"])\n",
    "#cmap.dropna(subset=\"iso2\", inplace=True)\n",
    "cmap.dropna(subset=\"eci\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_26257/214813710.py:7: FutureWarning: `idVariable` is deprecated and will be removed in future. Use `ids` instead.\n",
      "  w = weights.Queen.from_dataframe(cmap, idVariable=\"iso2\")\n",
      "/opt/homebrew/lib/python3.13/site-packages/libpysal/weights/contiguity.py:347: UserWarning: The weights matrix is not fully connected: \n",
      " There are 27 disconnected components.\n",
      " There are 22 islands with ids: CY, JM, LK, AU, PH, MG, KR, MU, JP, MT, SG, BH, BB, PR, SN, MV, IS, CU, RE, TW, NZ, TT.\n",
      "  W.__init__(self, neighbors, ids=ids, **kw)\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_26257/214813710.py:13: FutureWarning: `idVariable` is deprecated and will be removed in future. Use `ids` instead.\n",
      "  w = weights.Queen.from_dataframe(cmap, idVariable=\"iso2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4826942565066437 Moran's I\n",
      "0.001 significance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/libpysal/weights/contiguity.py:347: UserWarning: The weights matrix is not fully connected: \n",
      " There are 5 disconnected components.\n",
      "  W.__init__(self, neighbors, ids=ids, **kw)\n"
     ]
    }
   ],
   "source": [
    "### spatial autocorrelation\n",
    "\n",
    "# index setting\n",
    "cmap = cmap.set_index(\"iso2\", drop=False)\n",
    "\n",
    "# create the spatial weights matrix\n",
    "w = weights.Queen.from_dataframe(cmap, idVariable=\"iso2\")\n",
    "\n",
    "# drop island\n",
    "cmap = cmap.drop(w.islands)\n",
    "\n",
    "# create the spatial weights matrix\n",
    "w = weights.Queen.from_dataframe(cmap, idVariable=\"iso2\")\n",
    "\n",
    "# row standardize the matrix\n",
    "w.transform = \"R\"\n",
    "\n",
    "# spatial lag\n",
    "cmap[\"w_eci\"] = weights.lag_spatial(w, cmap[\"eci\"])\n",
    "\n",
    "# z score\n",
    "cmap[\"eci_std\"] = (cmap[\"eci\"] - cmap[\"eci\"].mean()) / cmap[\"eci\"].std()\n",
    "cmap[\"w_eci_std\"] = weights.lag_spatial(w, cmap[\"eci_std\"])\n",
    "\n",
    "# Moran I\n",
    "mi = esda.Moran(cmap[\"eci\"], w)\n",
    "print(mi.I, \"Moran's I\")\n",
    "print(mi.p_sim, \"significance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**comparison of ECI software measures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eci_software</th>\n",
       "      <th>eci_cluster_theory</th>\n",
       "      <th>eci_cluster_cooccurrence</th>\n",
       "      <th>eci_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eci_software</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981778</td>\n",
       "      <td>0.972761</td>\n",
       "      <td>0.839021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_cluster_theory</th>\n",
       "      <td>0.981778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968438</td>\n",
       "      <td>0.822590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_cluster_cooccurrence</th>\n",
       "      <td>0.972761</td>\n",
       "      <td>0.968438</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.816693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eci_topic</th>\n",
       "      <td>0.839021</td>\n",
       "      <td>0.822590</td>\n",
       "      <td>0.816693</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          eci_software  eci_cluster_theory  \\\n",
       "eci_software                  1.000000            0.981778   \n",
       "eci_cluster_theory            0.981778            1.000000   \n",
       "eci_cluster_cooccurrence      0.972761            0.968438   \n",
       "eci_topic                     0.839021            0.822590   \n",
       "\n",
       "                          eci_cluster_cooccurrence  eci_topic  \n",
       "eci_software                              0.972761   0.839021  \n",
       "eci_cluster_theory                        0.968438   0.822590  \n",
       "eci_cluster_cooccurrence                  1.000000   0.816693  \n",
       "eci_topic                                 0.816693   1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparison\n",
    "selected_year = 2021\n",
    "\n",
    "cluster_cdf1 = pd.read_csv(\"../../data/outputs/eci_clusters_theory_2020_2023.csv\", sep=\";\")\n",
    "cluster_cdf = pd.read_csv(\"../../data/outputs/eci_clusters_cooc_2020_2023.csv\", sep=\";\")\n",
    "eci_software = pd.read_csv(\"../../data/outputs/eci_software_2020_2023.csv\", sep=\";\")\n",
    "topic_cdf = pd.read_csv(\"../../data/outputs/eci_topics_2020_2023.csv\", sep=\";\")\n",
    "\n",
    "cc_df = pd.merge(\n",
    "    eci_software[eci_software[\"year\"]==selected_year][[\"iso2_code\", \"eci\"]].drop_duplicates(),\n",
    "    cluster_cdf[cluster_cdf[\"year\"]==selected_year][[\"iso2_code\", \"eci\"]].drop_duplicates(),\n",
    "    on=[\"iso2_code\"],\n",
    "    how=\"left\",\n",
    "    suffixes=[\"_software\", \"_cluster\"]\n",
    ")\n",
    "temp = pd.merge(\n",
    "    cc_df,\n",
    "    cluster_cdf1[cluster_cdf1[\"year\"]==selected_year][[\"iso2_code\", \"eci\"]].drop_duplicates(),\n",
    "    on=[\"iso2_code\"],\n",
    "    how=\"left\"\n",
    ").rename(columns={\"eci\":\"eci_cluster_theory\", \"eci_cluster\":\"eci_cluster_cooccurrence\"})\n",
    "temp = pd.merge(\n",
    "    temp,\n",
    "    topic_cdf[topic_cdf[\"year\"]==selected_year][[\"iso2_code\", \"eci\"]].drop_duplicates(),\n",
    "    on=[\"iso2_code\"],\n",
    "    how=\"left\"\n",
    ").rename(columns={\"eci\":\"eci_topic\"})\n",
    "\n",
    "temp[[\"eci_software\", \"eci_cluster_theory\", \"eci_cluster_cooccurrence\", \"eci_topic\"]].corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
