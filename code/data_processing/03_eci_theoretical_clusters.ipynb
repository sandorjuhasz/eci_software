{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from ecomplexity import ecomplexity\n",
    "from ecomplexity import proximity\n",
    "from ecomplexity import calc_density\n",
    "import country_converter as coco\n",
    "import itertools\n",
    "\n",
    "import yaml\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.config_utils import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "config = load_config()\n",
    "focal_year = config[\"focal_year\"]\n",
    "selected_period = config[\"selected_period\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**clustered languages -- theoretical version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93076, 7)\n"
     ]
    }
   ],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../../data/inputs/languages.csv\")\n",
    "\n",
    "# use data_prep_functions to clean the dataframe of ECI_software calculation\n",
    "data = data[data[\"year\"].isin([2020, 2021, 2022, 2023])]\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Percentage of pairs compared that meet log-supermodularity condition: 9.78%\n",
      "1\n",
      "2020  DONE\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 1: Log-supermodularity condition is not fully satisfied (9.78% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 10.50%\n",
      "2\n",
      "2021  DONE\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 2: Log-supermodularity condition is not fully satisfied (10.50% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 11.00%\n",
      "3\n",
      "2022  DONE\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 3: Log-supermodularity condition is not fully satisfied (11.00% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of pairs compared that meet log-supermodularity condition: 11.77%\n",
      "4\n",
      "2023  DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/ecomplexity/ecomplexity.py:252: UserWarning: Year 4: Log-supermodularity condition is not fully satisfied (11.77% of pairs compared satisfy this condition). The ECI and PCI values may not be a true representation of the complexity. More details at: https://growthlab.hks.harvard.edu/publications/structural-ranking-economic-complexity\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# clusters of languages\n",
    "cl_df = pd.read_csv(\"../../data/outputs/language_to_cluster_mapping.csv\")\\\n",
    "    .rename(columns={\"Language\":\"language\", \"Cluster\":\"cluster_id\", \"Cluster Name\":\"cluster_name\"})\n",
    "\n",
    "# combine\n",
    "cl_df = pd.merge(\n",
    "    df,\n",
    "    cl_df,\n",
    "    on=\"language\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# drop NAs... -- not so great\n",
    "cl_df.dropna(subset=[\"cluster_id\", \"cluster_name\"], inplace=True)\n",
    "\n",
    "# aggregate by clusters\n",
    "cl_df = cl_df.groupby([\"iso2_code\", \"period\", \"cluster_name\"])[\"num_pushers\"].agg(\"mean\").reset_index()\n",
    "\n",
    "# for ecomplexity calculcation\n",
    "key_cols = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"cluster_name\",\n",
    "    \"val\": \"num_pushers\",\n",
    "}\n",
    "\n",
    "# software complexity calculation -- period IDs -- 1 means 2020 on yearly basis\n",
    "ccdf = []\n",
    "ppdf = []\n",
    "year_dict = {1 : 2020, 2 : 2021, 3 : 2022, 4 : 2023}\n",
    "for k in year_dict.keys():\n",
    "    dfb = cl_df[cl_df[\"period\"]==k]\n",
    "    cdf = ecomplexity(dfb, key_cols)\n",
    "    cdf[\"year\"] = year_dict[k]\n",
    "\n",
    "    pdf = proximity(dfb, key_cols)\n",
    "    pdf[\"year\"] = year_dict[k]\n",
    "\n",
    "    # combine yearly dataframes\n",
    "    ccdf.append(cdf)\n",
    "    ppdf.append(pdf)\n",
    "    print(year_dict[k], \" DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and save -- complexity\n",
    "cluster_cdf = pd.concat(ccdf, axis=0, ignore_index=True)\n",
    "cluster_cdf.to_csv(\"../../data/outputs/eci_clusters_theory_2020_2023.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and save -- language-cluster proximity\n",
    "prox_df = pd.concat(ppdf, axis=0, ignore_index=True)\n",
    "prox_df.to_csv(\"../../data/outputs/proximity_clusters_theory_2020_2023.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93076, 7)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### ENTRY -- based on clusters\n",
    "\n",
    "# relatedness density -- as in Hidalgo et al. (2007) Science\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_theory_2020_2023.csv\", sep=\";\")\n",
    "rel_dens = cdf[cdf[\"year\"] == 2020][[\"iso2_code\", \"cluster_name\", \"density\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "# data IN\n",
    "data = pd.read_csv(\"../../data/inputs/languages.csv\")\n",
    "selected_period = \"year\"\n",
    "\n",
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)\n",
    "\n",
    "# clusters of languages\n",
    "cl_df = pd.read_csv(\"../../data/outputs/language_to_cluster_mapping.csv\")\\\n",
    "    .rename(columns={\"Language\":\"language\", \"Cluster\":\"cluster_id\", \"Cluster Name\":\"cluster_name\"})\n",
    "\n",
    "# combine\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    cl_df,\n",
    "    on=\"language\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# drop NAs... -- not so great\n",
    "df.dropna(subset=[\"cluster_id\", \"cluster_name\"], inplace=True)\n",
    "\n",
    "# aggregate by clusters\n",
    "df = df.groupby([\"iso2_code\", \"period\", \"cluster_name\"])[\"num_pushers\"].agg(\"mean\").reset_index()\n",
    "\n",
    "\n",
    "def bundle_data_clusters(data, periods):\n",
    "    \"\"\"aggreagte data for period by taking the mean number active developers\"\"\"\n",
    "    data = (\n",
    "        data[data[\"period\"].isin(periods)]\n",
    "        .groupby([\"iso2_code\", \"cluster_name\"])[\"num_pushers\"]\n",
    "        .agg(\"mean\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    data[\"period\"] = 1\n",
    "    data[\"num_pushers\"] = data[\"num_pushers\"].astype(int)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# threshold for RCA : 1.00\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data_clusters(df, periods=[p])\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"cluster_name\", value_column=\"num_pushers\", threshold=1))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)\n",
    "\n",
    "\n",
    "# identify entry following the given patterns\n",
    "entry_pattern = [0,0,1,1]\n",
    "consider_pattern = [0,0,0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"cluster_name\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"cluster_name\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"cluster_name\"])\\\n",
    "    .sort_values([\"iso2_code\", \"cluster_name\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"cluster_name\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_theory_2020_2023.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"cluster_name\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"cluster_name\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rel_dens,\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../../data/outputs/data_entry_regressions_0011_clusters_theory.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93076, 7)\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "### EXIT -- 1.00 threshold\n",
    "\n",
    "# relatedness density -- as in Hidalgo et al. (2007) Science\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_theory_2020_2023.csv\", sep=\";\")\n",
    "rel_dens = cdf[cdf[\"year\"] == 2020][[\"iso2_code\", \"cluster_name\", \"density\"]].drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "# data IN\n",
    "data = pd.read_csv(\"../../data/inputs/languages.csv\")\n",
    "selected_period = \"year\"\n",
    "\n",
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)\n",
    "\n",
    "# clusters of languages\n",
    "cl_df = pd.read_csv(\"../../data/outputs/language_to_cluster_mapping.csv\")\\\n",
    "    .rename(columns={\"Language\":\"language\", \"Cluster\":\"cluster_id\", \"Cluster Name\":\"cluster_name\"})\n",
    "\n",
    "# combine\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    cl_df,\n",
    "    on=\"language\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# drop NAs... -- not so great\n",
    "df.dropna(subset=[\"cluster_id\", \"cluster_name\"], inplace=True)\n",
    "\n",
    "# aggregate by clusters\n",
    "df = df.groupby([\"iso2_code\", \"period\", \"cluster_name\"])[\"num_pushers\"].agg(\"mean\").reset_index()\n",
    "\n",
    "\n",
    "def bundle_data_clusters(data, periods):\n",
    "    \"\"\"aggreagte data for period by taking the mean number active developers\"\"\"\n",
    "    data = (\n",
    "        data[data[\"period\"].isin(periods)]\n",
    "        .groupby([\"iso2_code\", \"cluster_name\"])[\"num_pushers\"]\n",
    "        .agg(\"mean\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    data[\"period\"] = 1\n",
    "    data[\"num_pushers\"] = data[\"num_pushers\"].astype(int)\n",
    "    return data\n",
    "\n",
    "\n",
    "# threshold for RCA : 1.00\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data_clusters(df, periods=[p])\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"cluster_name\", value_column=\"num_pushers\", threshold=1))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)\n",
    "\n",
    "\n",
    "\n",
    "# identify entry following the given patterns\n",
    "exit_pattern = [1,1,0,0]\n",
    "consider_pattern = [1,1,1,1]\n",
    "ext = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"cluster_name\"])[\"rca01\"].agg(list).reset_index()\n",
    "ext[\"entry01\"] = ext[\"rca01\"].apply(lambda x: x == exit_pattern).astype(int)\n",
    "ext[\"consider00\"] = ext[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# full combination\n",
    "all_countries = ext[\"iso2_code\"].unique()\n",
    "all_languages = ext[\"cluster_name\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"cluster_name\"])\\\n",
    "    .sort_values([\"iso2_code\", \"cluster_name\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ext[[\"iso2_code\", \"cluster_name\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../../data/outputs/eci_clusters_theory_2020_2023.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"cluster_name\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"cluster_name\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rel_dens,\n",
    "    on=[\"iso2_code\", \"cluster_name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df.rename(columns={\"entry01\":\"exit01\"}, inplace=True)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"exit01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../../data/outputs/data_exit_regressions_1100_clusters_theory.csv\", index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
