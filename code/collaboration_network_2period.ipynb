{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd2d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa7f86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_filter(G, weight='weight'):\n",
    "    ''' Compute significance scores (alpha) for weighted edges in G as defined in Serrano et al. 2009\n",
    "        Args\n",
    "            G: Weighted NetworkX graph\n",
    "        Returns\n",
    "            Weighted graph with a significance score (alpha) assigned to each edge\n",
    "        References\n",
    "            M. A. Serrano et al. (2009) Extracting the Multiscale backbone of complex weighted networks. \n",
    "            PNAS, 106:16, pp. 6483-6488.\n",
    "    '''\n",
    "    \n",
    "    if nx.is_directed(G): #directed case    \n",
    "        N = nx.DiGraph()\n",
    "        for u in G:\n",
    "            \n",
    "            k_out = G.out_degree(u)\n",
    "            k_in = G.in_degree(u)\n",
    "            \n",
    "            if k_out > 1:\n",
    "                sum_w_out = sum(np.absolute(G[u][v][weight]) for v in list(G.successors(u)))\n",
    "                for v in list(G.successors(u)):\n",
    "                    w = G[u][v][weight]\n",
    "                    p_ij_out = float(np.absolute(w))/sum_w_out\n",
    "                    alpha_ij_out = 1 - (k_out-1) * integrate.quad(lambda x: (1-x)**(k_out-2), 0, p_ij_out)[0]\n",
    "                    N.add_edge(u, v, weight = w, alpha_out=float('%.4f' % alpha_ij_out))\n",
    "                    \n",
    "            elif k_out == 1 and G.in_degree(list(G.successors(u))[0]) == 1:\n",
    "                #we need to keep the connection as it is the only way to maintain the connectivity of the network\n",
    "                v = list(G.successors(u))[0]\n",
    "                w = G[u][v][weight]\n",
    "                N.add_edge(u, v, weight = w, alpha_out=0., alpha_in=0.)\n",
    "                #there is no need to do the same for the k_in, since the link is built already from the tail\n",
    "            \n",
    "            if k_in > 1:\n",
    "                sum_w_in = sum(np.absolute(G[v][u][weight]) for v in G.predecessors(u))\n",
    "                for v in G.predecessors(u):\n",
    "                    w = G[v][u][weight]\n",
    "                    p_ij_in = float(np.absolute(w))/sum_w_in\n",
    "                    alpha_ij_in = 1 - (k_in-1) * integrate.quad(lambda x: (1-x)**(k_in-2), 0, p_ij_in)[0]\n",
    "                    N.add_edge(v, u, weight = w, alpha_in=float('%.4f' % alpha_ij_in))\n",
    "        return N\n",
    "    \n",
    "    else: #undirected case\n",
    "        B = nx.Graph()\n",
    "        for u in G:\n",
    "            k = len(G[u])\n",
    "            if k > 1:\n",
    "                sum_w = sum(np.absolute(G[u][v][weight]) for v in G[u])\n",
    "                for v in G[u]:\n",
    "                    w = G[u][v][weight]\n",
    "                    p_ij = float(np.absolute(w))/sum_w\n",
    "                    alpha_ij = 1 - (k-1) * integrate.quad(lambda x: (1-x)**(k-2), 0, p_ij)[0]\n",
    "                    B.add_edge(u, v, weight = w, alpha=float('%.4f' % alpha_ij))\n",
    "        return B\n",
    "\n",
    "def disparity_filter_alpha_cut(G,weight='weight',alpha_t=0.4, cut_mode='or'):\n",
    "    ''' Performs a cut of the graph previously filtered through the disparity_filter function.\n",
    "        \n",
    "        Args\n",
    "        ----\n",
    "        G: Weighted NetworkX graph\n",
    "        \n",
    "        weight: string (default='weight')\n",
    "            Key for edge data used as the edge weight w_ij.\n",
    "            \n",
    "        alpha_t: double (default='0.4')\n",
    "            The threshold for the alpha parameter that is used to select the surviving edges.\n",
    "            It has to be a number between 0 and 1.\n",
    "            \n",
    "        cut_mode: string (default='or')\n",
    "            Possible strings: 'or', 'and'.\n",
    "            It works only for directed graphs. It represents the logic operation to filter out edges\n",
    "            that do not pass the threshold value, combining the alpha_in and alpha_out attributes\n",
    "            resulting from the disparity_filter function.\n",
    "            \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        B: Weighted NetworkX graph\n",
    "            The resulting graph contains only edges that survived from the filtering with the alpha_t threshold\n",
    "    \n",
    "        References\n",
    "        ---------\n",
    "        .. M. A. Serrano et al. (2009) Extracting the Multiscale backbone of complex weighted networks. PNAS, \n",
    "        106:16, pp. 6483-6488.\n",
    "    '''    \n",
    "    \n",
    "    \n",
    "    if nx.is_directed(G):#Directed case:   \n",
    "        B = nx.DiGraph()\n",
    "        for u, v, w in G.edges(data=True):\n",
    "            try:\n",
    "                alpha_in =  w['alpha_in']\n",
    "            except KeyError: #there is no alpha_in, so we assign 1. It will never pass the cut\n",
    "                alpha_in = 1\n",
    "            try:\n",
    "                alpha_out =  w['alpha_out']\n",
    "            except KeyError: #there is no alpha_out, so we assign 1. It will never pass the cut\n",
    "                alpha_out = 1  \n",
    "            \n",
    "            if cut_mode == 'or':\n",
    "                if alpha_in<alpha_t or alpha_out<alpha_t:\n",
    "                    B.add_edge(u,v, weight=w[weight])\n",
    "            elif cut_mode == 'and':\n",
    "                if alpha_in<alpha_t and alpha_out<alpha_t:\n",
    "                    B.add_edge(u,v, weight=w[weight])\n",
    "        return B\n",
    "\n",
    "    else:\n",
    "        B = nx.Graph()#Undirected case:   \n",
    "        for u, v, w in G.edges(data=True):\n",
    "            \n",
    "            try:\n",
    "                alpha = w['alpha']\n",
    "            except KeyError: #there is no alpha, so we assign 1. It will never pass the cut\n",
    "                alpha = 1\n",
    "                \n",
    "            if alpha<alpha_t:\n",
    "                B.add_edge(u,v, weight=w[weight])\n",
    "        return B                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "987ba24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filtered_network(semester_weighted_el):\n",
    "    D=nx.DiGraph()\n",
    "    D.add_weighted_edges_from(semester_weighted_el[['source','destination','weight']].values)\n",
    "    D=disparity_filter(D)\n",
    "\n",
    "    filtered_graph=nx.Graph()\n",
    "    filtered = [(x[0],x[1]) for x in D.edges(data=True) if\n",
    "            x[2].get('alpha_out',1)<.1 and x[2].get('alpha_in',1)<.1]\n",
    "    filtered_graph.add_edges_from(filtered)\n",
    "    return filtered_graph\n",
    "\n",
    "def get_collaborators_semester(semester):\n",
    "    filtered_graph=make_filtered_network(semester_collab[semester_collab['period']==semester])\n",
    "    collabs=pd.DataFrame(filtered_graph.edges(),columns=['c1','c2'])\n",
    "    return collabs\n",
    "    \n",
    "def get_country_collaborators(country,collaborations):\n",
    "    collaborations_of_country =[]\n",
    "    for row in collaborations.iterrows():\n",
    "        if row[1].c1 == country:\n",
    "            collaborations_of_country.append(row[1].c2)\n",
    "        elif row[1].c2==country:\n",
    "            collaborations_of_country.append(row[1].c1)\n",
    "    return collaborations_of_country\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d66d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "el=pd.read_csv('../outputs/software_space_edgelist2020-2021.csv',sep=';')\n",
    "country_lang_rca=pd.read_csv(\"../outputs/entry_table_2periods.csv\",sep=\";\")\n",
    "country_lang_rca['period']= country_lang_rca['year'].map(lambda x: 1 if x in [2020,2021] else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a31159fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rca_dict=dict(\n",
    "    country_lang_rca[country_lang_rca['rca01']==1].groupby(['iso2_code','period']).language.apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13678392",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/economy_collaborators.csv') #read in data\n",
    "df=df[(df['source']!='EU')&(df['destination']!='EU')] #drop EU\n",
    "df=df.sort_values(['year','quarter'])\n",
    "df['period']= df['year'].map(lambda x: 1 if x in [2020,2021] else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97e92fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "semester_collab=df.groupby(['source','destination','period'])['weight'].sum().reset_index()\n",
    "semesters=sorted(semester_collab.period.unique())\n",
    "countries = list(set(list(df.source.unique())+list(df.destination.unique())))\n",
    "languages = list(country_lang_rca['language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d637962",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [] #country,semester,collaborator,language RCA>1\n",
    "all_csl_rca = [] #country,semester, language n RCA1\n",
    "for semester in semesters:\n",
    "    collabs=get_collaborators_semester(semester)\n",
    "    for country in countries:\n",
    "        collaborators=get_country_collaborators(country,collaborations = collabs)\n",
    "        csl_rca = []\n",
    "        if len(collaborators)>0:\n",
    "            for collaborator in collaborators:\n",
    "                if collaborator!=country:\n",
    "                    langs=list(set(rca_dict.get((collaborator,semester),[])))\n",
    "                    if len(langs)>0:\n",
    "                        for lang in langs:\n",
    "                            csl_rca.append((country,semester,lang))\n",
    "                        output.append([country,semester,collaborator,langs])\n",
    "        if len(csl_rca)>1:\n",
    "            all_csl_rca+=list(set(csl_rca))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7dc6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_semester_neighbor_RCA_lang=pd.DataFrame(all_csl_rca,columns=['country','period','neighbor_rca_lang'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "663cc5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_nl =dict(country_semester_neighbor_RCA_lang.groupby(['country','period'])['neighbor_rca_lang'].apply(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4de433f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel=pd.read_csv('../outputs/entry_reg_table_2periods.csv',sep=';')\n",
    "rel['period']= rel['year'].map(lambda x: 1 if x in [2020,2021] else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3112b787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "neighbor_related = []\n",
    "for row in rel.iterrows():\n",
    "    rel_langs=cs_nl.get((row[1]['iso2_code'],row[1]['period']),[])\n",
    "    if row[1]['language'] in rel_langs:\n",
    "        neighbor_related.append(1)\n",
    "    else:\n",
    "        neighbor_related.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fda4bc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    38495\n",
       "1     9781\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(neighbor_related).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1171e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel['neighbor_related']=neighbor_related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "117f0787",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel.to_csv('../outputs/relatedness_country_semester_panel_with_collab_neighbors_2p.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cce19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9fc93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176a274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5111ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d970c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0aa099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
