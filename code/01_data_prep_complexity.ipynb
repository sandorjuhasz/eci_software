{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from ecomplexity import ecomplexity\n",
    "from ecomplexity import proximity\n",
    "import country_converter as coco\n",
    "import itertools\n",
    "\n",
    "from data_prep_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 0 - general data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter to choose year / semester / quarter to construct period IDs\n",
    "selected_period = \"year\"\n",
    "\n",
    "# for ecomplexity calculcation\n",
    "key_cols = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"language\",\n",
    "    \"val\": \"num_pushers\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../data/languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88775, 7)\n"
     ]
    }
   ],
   "source": [
    "# use data_prep_functions to clean the dataframe of ECI_software calculation\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 - from M_cl to ECI_software and language proximity - based on yearly data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2020  DONE\n",
      "1\n",
      "1\n",
      "2021  DONE\n",
      "1\n",
      "1\n",
      "2022  DONE\n",
      "1\n",
      "1\n",
      "2023  DONE\n"
     ]
    }
   ],
   "source": [
    "# software complexity calculation -- period IDs -- 1 means 2020 on yearly basis\n",
    "ccdf = []\n",
    "ppdf = []\n",
    "year_dict = {1 : 2020, 2 : 2021, 3 : 2022, 4 : 2023}\n",
    "for k in year_dict.keys():\n",
    "    dfb = bundle_data(df, periods=[k])\n",
    "    cdf = ecomplexity(dfb, key_cols)\n",
    "    cdf[\"year\"] = year_dict[k]\n",
    "\n",
    "    pdf = proximity(dfb, key_cols)\n",
    "    pdf[\"year\"] = year_dict[k]\n",
    "\n",
    "    # combine yearly dataframes\n",
    "    ccdf.append(cdf)\n",
    "    ppdf.append(pdf)\n",
    "    print(year_dict[k], \" DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and save -- complexity\n",
    "cdf = pd.concat(ccdf, axis=0, ignore_index=True)\n",
    "cdf.to_csv(\"../outputs/eci_software_2020_2023.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine and save -- language proximity\n",
    "prox_df = pd.concat(ppdf, axis=0, ignore_index=True)\n",
    "prox_df.to_csv(\"../outputs/proximity_2020_2023.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 - comparing ECI(software, trade, technology, research)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in developers (for filtering option)\n",
    "df = pd.read_csv(\"../data/developers.csv\")\n",
    "df = df.groupby([\"iso2_code\", \"year\"])[\"developers\"].agg(\"mean\").reset_index()\n",
    "df[\"developers\"] = df[\"developers\"].astype(int)\n",
    "df = df[df[\"year\"]==2020]\n",
    "\n",
    "# add ECI_software\n",
    "eci_software = pd.read_csv(\"../outputs/eci_software_2020_2023.csv\", sep=\";\")\n",
    "eci_software = eci_software[eci_software[\"year\"]==2020]\n",
    "country_to_seci_2020 = dict(zip(eci_software[\"iso2_code\"], eci_software[\"eci\"]))\n",
    "df[\"software_eci_2020\"] = df[\"iso2_code\"].map(country_to_seci_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 3 other ECI measures\n",
    "trade_eci = pd.read_csv(\"../data/eci_hs6_hs96_trade.csv\")\n",
    "trade_eci = trade_eci[[\"Country\", \"2020\"]]\n",
    "tech_eci = pd.read_csv(\"../data/eci_tech.csv\")\n",
    "tech_eci = tech_eci[[\"Country\", \"2020\"]]\n",
    "research_eci = pd.read_csv(\"../data/Data-ECI-Research.csv\")\n",
    "research_eci = research_eci[[\"Country\", \"2020\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map country names to iso2_codes - using the country_converter package\n",
    "c_to_iso = dict(\n",
    "    zip(trade_eci.Country.unique(), coco.convert(names=trade_eci.Country.unique(), to=\"ISO2\")))\n",
    "trade_eci[\"Country\"] = trade_eci[\"Country\"].map(c_to_iso)\n",
    "iso_to_trade_eci = dict(trade_eci.values)\n",
    "df[\"trade_eci_2020\"] = df[\"iso2_code\"].map(iso_to_trade_eci)\n",
    "\n",
    "tech_eci[\"Country\"] = tech_eci[\"Country\"].map(c_to_iso)\n",
    "iso_to_tech_eci = dict(tech_eci.values)\n",
    "df[\"tech_eci_2020\"] = df[\"iso2_code\"].map(iso_to_tech_eci)\n",
    "\n",
    "research_eci[\"Country\"] = research_eci[\"Country\"].map(c_to_iso)\n",
    "iso_to_research_eci = dict(research_eci.values)\n",
    "df[\"research_eci_2020\"] = df[\"iso2_code\"].map(iso_to_research_eci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_18621/1367150806.py:2: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trade_df = pd.read_csv(\"../data/Gravity_V202211.csv\")\n"
     ]
    }
   ],
   "source": [
    "# data from CEPII -- http://www.cepii.fr/CEPII/en/bdd_modele/bdd_modele_item.asp?id=8\n",
    "trade_df = pd.read_csv(\"../data/Gravity_V202211.csv\")\n",
    "trade_df = trade_df[trade_df[\"year\"] == 2020]\n",
    "trade_df['country_id_o'] = trade_df['country_id_o'].map(lambda x: x.replace('.2',''))\n",
    "trade_df['country_id_d'] = trade_df['country_id_d'].map(lambda x: x.replace('.2',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ANT not found in ISO3\n",
      "CSK not found in ISO3\n",
      "DDR not found in ISO3\n",
      "SCG not found in ISO3\n",
      "SUN not found in ISO3\n",
      "VDR not found in ISO3\n",
      "YMD not found in ISO3\n",
      "YUG not found in ISO3\n"
     ]
    }
   ],
   "source": [
    "# code transformation\n",
    "iso3_codes = pd.concat([trade_df[\"iso3_o\"], trade_df[\"iso3_d\"]]).unique().tolist()\n",
    "iso2_codes = coco.convert(names=iso3_codes, to=\"ISO2\")\n",
    "codes = pd.DataFrame(iso3_codes, iso2_codes).reset_index()\n",
    "codes.columns = [\"iso2_code\", \"iso3_code\"]\n",
    "\n",
    "trade_df = pd.merge(\n",
    "    trade_df,\n",
    "    codes,\n",
    "    left_on=\"iso3_o\",\n",
    "    right_on=\"iso3_code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# keep useful country data and join to \n",
    "key_country_info = [\n",
    "    \"year\",\n",
    "    \"iso3_code\",\n",
    "    \"iso2_code\",\n",
    "    \"pop_o\",\n",
    "    \"gdp_o\",\n",
    "    \"gdpcap_o\",\n",
    "    \"gdp_ppp_o\",\n",
    "    \"gdpcap_ppp_o\"\n",
    "]\n",
    "country_info = trade_df[key_country_info].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine country info the ECI collector dataframe\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    country_info,\n",
    "    on=[\"iso2_code\", \"year\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add GINI -- https://data.worldbank.org/indicator/SI.POV.GINI\n",
    "gini_df = pd.read_excel(\"../data/gini_worldbank_data.xls\")\n",
    "\n",
    "# too many NAs -- take the average across 10+ years\n",
    "years_list = [str(year) for year in range(2010, 2020)]\n",
    "gini_df[\"gini_mean\"] = gini_df[years_list].mean(axis=1)\n",
    "gini_df = gini_df[[\"Country Code\", \"gini_mean\"]]\n",
    "gini_df.columns = [\"iso3_code\", \"gini_mean\"]\n",
    "gini_df.dropna(subset=\"gini_mean\", inplace=True)\n",
    "\n",
    "# join iso2_codes -- create above\n",
    "gini_df = pd.merge(\n",
    "    gini_df,\n",
    "    codes,\n",
    "    on=\"iso3_code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "gini_df.dropna(subset=\"iso2_code\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine GINI with ECI collector dataframe\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    gini_df,\n",
    "    on=[\"iso2_code\", \"iso3_code\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add emissions -- new data from Viktor -- ask about preparation details\n",
    "emdf = pd.read_csv(\"../data/regressions_emissions_data.csv\")\n",
    "emdf = emdf[[\"country\", \"emissions\", \"nat_res\"]].drop_duplicates()\n",
    "\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    emdf,\n",
    "    left_on=\"iso3_code\",\n",
    "    right_on=\"country\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "df.to_csv(\"../outputs/eci_comparisons_2020.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2b - matrices based on trade/research/publications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_reshape(path, column_labels):\n",
    "    \"\"\"to reshape the matrices from Viktor Stojkoski\"\"\"\n",
    "    mat = pd.read_csv(path)\n",
    "    mat.set_index(\"Row\", inplace=True)\n",
    "    mat = mat.unstack().reset_index()\n",
    "    mat.columns = column_labels\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ANT not found in ISO3\n",
      "YUG not found in ISO3\n",
      "CSE not found in ISO3\n",
      "DDE not found in ISO3\n",
      "EPO not found in ISO3\n",
      "XKO not found in ISO3\n",
      "SFE not found in ISO3\n",
      "SUE not found in ISO3\n",
      "XTP not found in ISO3\n",
      "XUB not found in ISO3\n",
      "FST not found in ISO3\n",
      "PIT not found in ISO3\n"
     ]
    }
   ],
   "source": [
    "# read and reshape matrices\n",
    "trade_df = mat_reshape(path=\"../data/stojkoski_etal_data/trade_matrix_data_2020.csv\", column_labels=[\"product\", \"iso3_code\", \"value\"])\n",
    "patent_df = mat_reshape(path=\"../data/stojkoski_etal_data/pct_data_2020.csv\", column_labels=[\"class\", \"iso3_code\", \"value\"])\n",
    "research_df = mat_reshape(path=\"../data/stojkoski_etal_data/pub_matrix_data_2020.csv\", column_labels=[\"category\", \"iso3_code\", \"value\"])\n",
    "\n",
    "# country code correction\n",
    "iso3_codes = pd.concat([trade_df[\"iso3_code\"], patent_df[\"iso3_code\"], research_df[\"iso3_code\"]]).unique().tolist()\n",
    "iso2_codes = coco.convert(names=iso3_codes, to=\"ISO2\")\n",
    "codes2 = pd.DataFrame(iso3_codes, iso2_codes).reset_index()\n",
    "codes2.columns = [\"iso2_code\", \"iso3_code\"]\n",
    "\n",
    "trade_df = pd.merge(\n",
    "    trade_df,\n",
    "    codes2,\n",
    "    on=\"iso3_code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "trade_df = trade_df[trade_df[\"iso2_code\"] != \"not found\"]\n",
    "\n",
    "patent_df = pd.merge(\n",
    "    patent_df,\n",
    "    codes2,\n",
    "    on=\"iso3_code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "patent_df = patent_df[patent_df[\"iso2_code\"] != \"not found\"]\n",
    "\n",
    "research_df = pd.merge(\n",
    "    research_df,\n",
    "    codes2,\n",
    "    on=\"iso3_code\",\n",
    "    how=\"left\"\n",
    ")\n",
    "research_df = research_df[research_df[\"iso2_code\"] != \"not found\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_78468/2382482397.py:2: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  grav_df = pd.read_csv(\"../data/Gravity_V202211.csv\")\n"
     ]
    }
   ],
   "source": [
    "# country level info from the gravity dataset\n",
    "grav_df = pd.read_csv(\"../data/Gravity_V202211.csv\")\n",
    "grav_df = grav_df[grav_df[\"year\"] == 2020]\n",
    "grav_df['country_id_o'] = grav_df['country_id_o'].map(lambda x: x.replace('.2',''))\n",
    "grav_df['country_id_d'] = grav_df['country_id_d'].map(lambda x: x.replace('.2',''))\n",
    "\n",
    "# population above 1 million\n",
    "countries_1m_pop = list(set(grav_df[grav_df[\"pop_o\"]>1000][\"iso3_o\"].to_list()))\n",
    "trade_df = trade_df[trade_df[\"iso3_code\"].isin(countries_1m_pop)]\n",
    "patent_df = patent_df[patent_df[\"iso3_code\"].isin(countries_1m_pop)]\n",
    "research_df = research_df[research_df[\"iso3_code\"].isin(countries_1m_pop)]\n",
    "\n",
    "# total export value of 1 billion USD\n",
    "above_1b_export = trade_df.groupby([\"iso2_code\"])[\"value\"].agg(\"sum\").reset_index()\n",
    "above_1b_export = list(set(above_1b_export[above_1b_export[\"value\"]>10**9][\"iso2_code\"].to_list()))\n",
    "trade_df = trade_df[trade_df[\"iso2_code\"].isin(above_1b_export)]\n",
    "\n",
    "# MIN 4 patent\n",
    "min4_patents = patent_df.groupby([\"iso2_code\"])[\"value\"].agg(\"sum\").reset_index()\n",
    "min4_patents = list(set(min4_patents[min4_patents[\"value\"] > 4][\"iso2_code\"].to_list()))\n",
    "patent_df = patent_df[patent_df[\"iso2_code\"].isin(min4_patents)]\n",
    "\n",
    "# countries w/ MIN 100 publications in a year - category w/ more than 30 published papers a year\n",
    "min100_publications = research_df.groupby([\"iso2_code\"])[\"value\"].agg(\"sum\").reset_index()\n",
    "min100_publications = list(set(min100_publications[min100_publications[\"value\"] >= 100][\"iso2_code\"].to_list()))\n",
    "min30_papers = research_df.groupby([\"category\"])[\"value\"].agg(\"sum\").reset_index()\n",
    "min30_papers = list(set(min30_papers[min30_papers[\"value\"] >= 30][\"category\"].to_list()))\n",
    "research_df = research_df[(research_df[\"category\"].isin(min30_papers))]\n",
    "\n",
    "# replace below 3 papers per country/category to 0\n",
    "research_df[\"value\"] = np.where(research_df[\"value\"]<3, 0, research_df[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace below avg 100 citations per country/category to 0\n",
    "years = [2017, 2018, 2019, 2020]\n",
    "citations = []\n",
    "for y in years:\n",
    "    temp = mat_reshape(path=f\"../data/stojkoski_etal_data/cit_matrix_data_{y}.csv\", column_labels=[\"category\", \"iso3_code\", \"citations\"])\n",
    "    temp[\"year\"] = y\n",
    "    citations.append(temp)\n",
    "\n",
    "citations = pd.concat(citations)\n",
    "citations = citations.groupby([\"category\", \"iso3_code\"])[\"citations\"].agg(\"mean\").reset_index()\n",
    "\n",
    "research_df = pd.merge(\n",
    "    research_df,\n",
    "    citations,\n",
    "    on=[\"iso3_code\", \"category\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "research_df[\"value\"] = np.where(research_df[\"citations\"]<100, 0, research_df[\"value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# calculate complexity and mcp\n",
    "key_cols_trade = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"product\",\n",
    "    \"val\": \"value\",\n",
    "}\n",
    "trade_df[\"period\"] = 1\n",
    "trade_cdf = ecomplexity(trade_df, key_cols_trade)\n",
    "\n",
    "key_cols_patent = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"class\",\n",
    "    \"val\": \"value\",\n",
    "}\n",
    "patent_df[\"period\"] = 1\n",
    "patent_cdf = ecomplexity(patent_df, key_cols_patent)\n",
    "\n",
    "key_cols_research = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"category\",\n",
    "    \"val\": \"value\",\n",
    "}\n",
    "research_df[\"period\"] = 1\n",
    "research_cdf = ecomplexity(research_df, key_cols_research)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for figures\n",
    "trade_cdf.to_csv(\"../outputs/trade_cdf_2020.csv\", sep=\";\", index=False)\n",
    "patent_cdf.to_csv(\"../outputs/patent_cdf_2020.csv\", sep=\";\", index=False)\n",
    "research_cdf.to_csv(\"../outputs/research_cdf_2020.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso2_code</th>\n",
       "      <th>eci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15604</th>\n",
       "      <td>GM</td>\n",
       "      <td>1.522059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18232</th>\n",
       "      <td>HT</td>\n",
       "      <td>1.408651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29558</th>\n",
       "      <td>MW</td>\n",
       "      <td>1.262951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21939</th>\n",
       "      <td>KE</td>\n",
       "      <td>1.229530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>CD</td>\n",
       "      <td>1.223756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47179</th>\n",
       "      <td>VN</td>\n",
       "      <td>-2.133784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38113</th>\n",
       "      <td>SA</td>\n",
       "      <td>-2.336082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19929</th>\n",
       "      <td>IN</td>\n",
       "      <td>-2.374740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>CN</td>\n",
       "      <td>-2.436940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>DZ</td>\n",
       "      <td>-2.512508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      iso2_code       eci\n",
       "15604        GM  1.522059\n",
       "18232        HT  1.408651\n",
       "29558        MW  1.262951\n",
       "21939        KE  1.229530\n",
       "6953         CD  1.223756\n",
       "...         ...       ...\n",
       "47179        VN -2.133784\n",
       "38113        SA -2.336082\n",
       "19929        IN -2.374740\n",
       "8962         CN -2.436940\n",
       "11847        DZ -2.512508\n",
       "\n",
       "[157 rows x 2 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_cdf[[\"iso2_code\", \"eci\"]].sort_values(by=\"eci\", ascending=False).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 - relatedness from proximity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from relatedness table to software space (MST w/ additional edges)\n",
    "rel_df = pd.read_csv(\"../outputs/proximity_2020_2023.csv\", sep=\";\")\n",
    "spaces = []\n",
    "years = [2020, 2021, 2022, 2023]\n",
    "for y in years:\n",
    "    space_table = edgelist_cleaning_for_software_space(rel_df[rel_df[\"year\"]==y], key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "    mst_el = maximum_spanning_tree(space_table, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "    mst_graph = nx.from_pandas_edgelist(mst_el, source=\"language_1\", target=\"language_2\")\n",
    "    n_nodes = mst_graph.number_of_nodes()\n",
    "    n_edges = n_nodes * 2\n",
    "    software_space_el = add_edges(mst_el, space_table, nr_edges_to_add=n_edges)\n",
    "    software_space_el[\"year\"] = y\n",
    "    spaces.append(software_space_el)\n",
    "\n",
    "# combine and export -- relatedness\n",
    "relatedness = pd.concat(spaces, axis=0, ignore_index=True)\n",
    "relatedness.to_csv(\"../outputs/relatedness_2020_2023.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3b - regression data for entry models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88775, 7)\n"
     ]
    }
   ],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../data/languages.csv\")\n",
    "selected_period = \"year\"\n",
    "\n",
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# threshold for RCA : 1\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data(df, periods=[p])\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\", threshold=1))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify entry following the given patterns\n",
    "entry_pattern = [0,0,1,1]\n",
    "consider_pattern = [0,0,0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../outputs/eci_software_2020_2023.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_68705/2602815770.py:11: FutureWarning: The provided callable <function sum at 0x106af6020> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  relatedness = pd.pivot_table(\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_68705/2602815770.py:23: FutureWarning: The provided callable <function sum at 0x106af6020> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  mat = pd.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "# calculate relatedness density \n",
    "software_space_el = pd.read_csv(\"../outputs/relatedness_2020_2023.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# common dimension based on the baseline period and relatedness\n",
    "base_l = list(rca_tables[rca_tables[\"period\"]==3][\"language\"].unique())\n",
    "rel_l = list(set(software_space_el[\"language_1\"] + software_space_el[\"language_2\"]))\n",
    "language_limit = list(set(base_l + rel_l))\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el[(software_space_el[\"language_1\"].isin(language_limit)) & (software_space_el[\"language_2\"].isin(language_limit))],\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_entry_regressions_0011.csv\", index=False, sep=\";\")\n",
    "#export_df.to_csv(\"../outputs/data_entry_regressions_0011_threshold05.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# threshold for RCA : 0.25, 1 -- backup\n",
    "ps1 = [1, 2]\n",
    "rca_tables1 = []\n",
    "for p in ps1:\n",
    "    print(p)\n",
    "    temp = bundle_data(df, periods=[p])\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables1.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\", threshold=0.5))\n",
    "\n",
    "ps2 = [3, 4]\n",
    "rca_tables2 = []\n",
    "for p in ps2:\n",
    "    print(p)\n",
    "    temp = bundle_data(df, periods=[p])\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables2.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\", threshold=0.1))\n",
    "\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables1 = pd.concat(rca_tables1)\n",
    "rca_tables2 = pd.concat(rca_tables2)\n",
    "rca_tables = pd.concat([rca_tables1, rca_tables2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4 - regression data for exit models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88775, 7)\n"
     ]
    }
   ],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../data/languages.csv\")\n",
    "selected_period = \"year\"\n",
    "\n",
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# threshold for RCA : 1\n",
    "ps = [1, 2, 3, 4]\n",
    "rca_tables = []\n",
    "for p in ps:\n",
    "    print(p)\n",
    "    temp = bundle_data(df, periods=[p])\n",
    "    temp[\"period\"] = p\n",
    "    rca_tables.append(rca_calculation(temp, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\", threshold=1))\n",
    "\n",
    "#    dfbs.append(temp)\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify entry following the given patterns\n",
    "exit_pattern = [1,1,0,0]\n",
    "consider_pattern = [1,1,1,1]\n",
    "ext = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ext[\"entry01\"] = ext[\"rca01\"].apply(lambda x: x == exit_pattern).astype(int)\n",
    "ext[\"consider00\"] = ext[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ext[\"iso2_code\"].unique()\n",
    "all_languages = ext[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ext[[\"iso2_code\", \"language\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../outputs/eci_software_2020_2023.csv\", sep=\";\")\n",
    "cdf = cdf[cdf[\"year\"]==2020]\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\", \"ubiquity\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_72066/2602815770.py:11: FutureWarning: The provided callable <function sum at 0x10a9fa0c0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  relatedness = pd.pivot_table(\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_72066/2602815770.py:23: FutureWarning: The provided callable <function sum at 0x10a9fa0c0> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  mat = pd.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "# calculate relatedness density \n",
    "software_space_el = pd.read_csv(\"../outputs/relatedness_2020_2023.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# common dimension based on the baseline period and relatedness\n",
    "base_l = list(rca_tables[rca_tables[\"period\"]==3][\"language\"].unique())\n",
    "rel_l = list(set(software_space_el[\"language_1\"] + software_space_el[\"language_2\"]))\n",
    "language_limit = list(set(base_l + rel_l))\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el[(software_space_el[\"language_1\"].isin(language_limit)) & (software_space_el[\"language_2\"].isin(language_limit))],\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df.rename(columns={\"entry01\":\"exit01\"}, inplace=True)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"exit01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_exit_regressions_1100.csv\", index=False, sep=\";\")\n",
    "#export_df.to_csv(\"../outputs/data_entry_regressions_0011_threshold05.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfbs[\"period\"].unique():\n",
    "    rca_df = dfbs[dfbs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\", threshold=1))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rca_tables.period.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify entry following the given patterns\n",
    "entry_pattern = [0,1]\n",
    "consider_pattern = [0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "cdf = pd.read_csv(\"../outputs/software_complexity_2020_2021_based.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_59097/465400437.py:11: FutureWarning: The provided callable <function sum at 0x1109f6020> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  relatedness = pd.pivot_table(\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_59097/465400437.py:23: FutureWarning: The provided callable <function sum at 0x1109f6020> is currently using DataFrameGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  mat = pd.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "# calculate relatedness density \n",
    "software_space_el = pd.read_csv(\"../outputs/software_space_edgelist_2020_2021_based.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# common dimension based on the baseline period and relatedness\n",
    "base_l = list(rca_tables[rca_tables[\"period\"]==3][\"language\"].unique())\n",
    "rel_l = list(set(software_space_el[\"language_1\"] + software_space_el[\"language_2\"]))\n",
    "language_limit = list(set(base_l + rel_l))\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el[(software_space_el[\"language_1\"].isin(language_limit)) & (software_space_el[\"language_2\"].isin(language_limit))],\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_entry_regressions_2020_2021_based.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**currently backup -- 3 most similar countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select year\n",
    "year_list = [2020, 2021, 2022, 2023]\n",
    "for y in year_list:\n",
    "    print(y)\n",
    "\n",
    "    cdf = cdf[cdf[\"year\"] == y]\n",
    "    cdf.year.isna().sum()\n",
    "\n",
    "    # generate full product dataframe\n",
    "    locations = list(set(cdf[\"iso2_code\"].to_list()))\n",
    "    full_prod_countries = pd.DataFrame(itertools.product(locations, repeat=2), columns=[\"iso2_code1\", \"iso2_code2\"])\n",
    "\n",
    "\n",
    "    # add location - mcp array to location pairs\n",
    "    mcp_temp = cdf.groupby(\"iso2_code\")[\"mcp\"].apply(np.array).reset_index()\n",
    "    full_prod_countries = pd.merge(\n",
    "        full_prod_countries,\n",
    "        mcp_temp,\n",
    "        left_on=\"iso2_code1\",\n",
    "        right_on=\"iso2_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    full_prod_countries = pd.merge(\n",
    "        full_prod_countries,\n",
    "        mcp_temp,\n",
    "        left_on=\"iso2_code2\",\n",
    "        right_on=\"iso2_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    full_prod_countries = full_prod_countries\\\n",
    "        .drop(columns=[\"iso2_code_x\", \"iso2_code_y\"])\\\n",
    "        .rename(columns={\"mcp_x\":\"mcp_array1\", \"mcp_y\":\"mcp_array2\"})\n",
    "\n",
    "    # minimum conditional probability -- to measure similarity between locations\n",
    "    full_prod_countries[\"spec_similarity\"] = full_prod_countries.apply(lambda r: round(sum(r[\"mcp_array1\"] * r[\"mcp_array2\"]) / max(sum(r[\"mcp_array1\"]), sum(r[\"mcp_array2\"])), 3), axis=1)\n",
    "\n",
    "    # drop iso2_code1 == iso2_code2 cases and keep the top3 most similar countries\n",
    "    sim_spec_df = full_prod_countries[full_prod_countries[\"iso2_code1\"] != full_prod_countries[\"iso2_code2\"]]\n",
    "    sim_spec_df = sim_spec_df.groupby([\"iso2_code1\"])[\"spec_similarity\"]\\\n",
    "        .nlargest(3)\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns={\"level_1\":\"iso2_code2_index\"})\n",
    "\n",
    "    # merge similar location names by index\n",
    "    sim_spec_df = pd.merge(\n",
    "        sim_spec_df,\n",
    "        full_prod_countries[[\"iso2_code2\"]].reset_index(),\n",
    "        left_on=\"iso2_code2_index\",\n",
    "        right_on=\"index\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # merge ECI values by location name\n",
    "    sim_spec_df = pd.merge(\n",
    "        sim_spec_df,\n",
    "        cdf[[\"iso2_code\", \"eci\"]].drop_duplicates(),\n",
    "        left_on=\"iso2_code2\",\n",
    "        right_on=\"iso2_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # merge distance values by location name\n",
    "    sim_spec_df = pd.merge(\n",
    "        sim_spec_df,\n",
    "        full_prod_countries,\n",
    "        on=[\"iso2_code1\", \"iso2_code2\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # average ECI of the top 3 most similar location \n",
    "    avg_comp_sim_spec = sim_spec_df.groupby([\"iso2_code1\"])\\\n",
    "        .agg(\n",
    "            avg_eci_similar_spec = pd.NamedAgg(\"eci\", np.mean))\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns={\"iso2_code1\" : \"iso2_code\"})\n",
    "\n",
    "    # join to full comb table\n",
    "    cdf = pd.merge(\n",
    "        cdf,\n",
    "        avg_comp_sim_spec,\n",
    "        on=\"iso2_code\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    #cdf.to_csv(f\"../outputs/software_complexity_{y}_based.csv\", index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
