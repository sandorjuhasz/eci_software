{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from itertools import product\n",
    "from ecomplexity import ecomplexity\n",
    "from ecomplexity import proximity\n",
    "import country_converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 0 - general data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter to choose year / semester / quarter to construct period IDs\n",
    "selected_period = \"year\"\n",
    "\n",
    "# for ecomplexity calculcation\n",
    "key_cols = {\n",
    "    \"time\": \"period\",\n",
    "    \"loc\": \"iso2_code\",\n",
    "    \"prod\": \"language\",\n",
    "    \"val\": \"num_pushers\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data IN\n",
    "data = pd.read_csv(\"../data/languages.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter functions\n",
    "def drop_specifics_from_list(data, filter_list):\n",
    "    \"\"\"filter specific languages from list -- motivated by RM del Rio-Chanona et al 2023\"\"\"\n",
    "    data = data[~data[\"language\"].str.contains(filter_list, case=False, regex=True)]\n",
    "    return data\n",
    "\n",
    "def top_languages_filter(data, nr_languages):\n",
    "    \"\"\"keep top x number of languages ONLY\"\"\"\n",
    "    top_languages = data.groupby([\"language\"])[\"num_pushers\"].agg(\"sum\").reset_index().sort_values(by=\"num_pushers\", ascending=False)\n",
    "    top_languages = list(top_languages[\"language\"])[:nr_languages]\n",
    "    data = data[data[\"language\"].isin(top_languages)]\n",
    "    return data\n",
    "    \n",
    "def drop_country_codes_from_list(data, country_list):\n",
    "    data = data[~data[\"iso2_code\"].isin(country_list)]\n",
    "    data = data.dropna(subset=\"iso2_code\")\n",
    "    return data\n",
    "\n",
    "def add_period_ids(data, period):\n",
    "    \"\"\"create missing semester ID and construct different period IDs\"\"\"\n",
    "    if period==\"year\":\n",
    "        year_to_period = dict(zip(data[\"year\"].unique(), list(range(1, len(data[\"year\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"year\"].map(year_to_period)\n",
    "    if period==\"semester\":\n",
    "        data[\"semester\"] = np.where(data[\"quarter\"] <= 2, 1, 2)\n",
    "        data[\"semester_id\"] = data[\"year\"].astype(str).str.cat(data[\"semester\"].astype(str), sep=\"s\")\n",
    "        semester_to_period = dict(zip(data[\"semester_id\"].unique(), list(range(1, len(data[\"semester_id\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"semester_id\"].map(semester_to_period)\n",
    "    if period==\"quarter\":\n",
    "        data[\"quarter_id\"] = data[\"year\"].astype(str).str.cat(data[\"quarter\"].astype(str), sep=\"q\")\n",
    "        quarter_to_period = dict(zip(data[\"quarter_id\"].unique(), list(range(1, len(data[\"quarter_id\"].unique()) + 1))))\n",
    "        data[\"period\"] = data[\"quarter_id\"].map(quarter_to_period)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84934, 7)\n"
     ]
    }
   ],
   "source": [
    "# steps to prep dataframe of ecomplexity\n",
    "prev_filter = \"|\".join([\"yaml\", \"json\", \"text\", \"svg\", \"Markdown\", \"xml\"])\n",
    "df = drop_specifics_from_list(data, filter_list=prev_filter)\n",
    "df = top_languages_filter(df, nr_languages=150)\n",
    "df = drop_country_codes_from_list(df, country_list=[\"EU\"])\n",
    "df = add_period_ids(df, period=selected_period)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1 - from M_cl to complexity and relatedness - based on 2020,2021 data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle data for M_cl\n",
    "def bundle_data(data, periods):\n",
    "    data = data[data[\"period\"].isin(periods)]\\\n",
    "        .groupby([\"iso2_code\", \"language\"])[\"num_pushers\"]\\\n",
    "        .agg(\"sum\")\\\n",
    "        .reset_index()\n",
    "    data[\"period\"] = 1\n",
    "    return data\n",
    "\n",
    "# period IDs -- 1,2 means 2020, 2021 on yearly basis\n",
    "dfb = bundle_data(df, periods=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# software complexity calculation\n",
    "cdf = ecomplexity(dfb, key_cols)\n",
    "cdf.to_csv(\"../outputs/software_complexity_2020_2021_based.csv\", index=False, sep=\";\")\n",
    "\n",
    "# software relatedness calculation\n",
    "rel_df = proximity(dfb, key_cols)\n",
    "rel_df.to_csv(\"../outputs/software_relatedness_2020_2021_based.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 - comparing ECI(software, trade, technology, research)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in developers (for filtering option)\n",
    "df = pd.read_csv(\"../data/developers.csv\")\n",
    "df = df.groupby([\"iso2_code\", \"year\"])[\"developers\"].agg(\"mean\").reset_index()\n",
    "df[\"developers\"] = df[\"developers\"].astype(int)\n",
    "df = df[df[\"year\"]==2020]\n",
    "\n",
    "# add software ECI\n",
    "cdf = pd.read_csv(\"../outputs/software_complexity_2020_2021_based.csv\", sep=\";\")\n",
    "country_to_seci_2020 = dict(cdf.groupby([\"iso2_code\"])[\"eci\"].mean())\n",
    "df[\"software_eci_2020\"] = df[\"iso2_code\"].map(country_to_seci_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in 3 other ECI measures\n",
    "trade_eci = pd.read_csv(\"../data/eci_hs6_hs96_trade.csv\")\n",
    "trade_eci = trade_eci[[\"Country\", \"2020\"]]\n",
    "tech_eci = pd.read_csv(\"../data/eci_tech.csv\")\n",
    "tech_eci = tech_eci[[\"Country\", \"2020\"]]\n",
    "research_eci = pd.read_csv(\"../data/Data-ECI-Research.csv\")\n",
    "research_eci = research_eci[[\"Country\", \"2020\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map - using the country_converter package to \n",
    "c_to_iso = dict(\n",
    "    zip(trade_eci.Country.unique(), country_converter.convert(names=trade_eci.Country.unique(), to=\"ISO2\")))\n",
    "trade_eci[\"Country\"] = trade_eci[\"Country\"].map(c_to_iso)\n",
    "iso_to_trade_eci = dict(trade_eci.values)\n",
    "df[\"trade_eci_2020\"] = df[\"iso2_code\"].map(iso_to_trade_eci)\n",
    "\n",
    "tech_eci[\"Country\"] = tech_eci[\"Country\"].map(c_to_iso)\n",
    "iso_to_tech_eci = dict(tech_eci.values)\n",
    "df[\"tech_eci_2020\"] = df[\"iso2_code\"].map(iso_to_tech_eci)\n",
    "\n",
    "research_eci[\"Country\"] = research_eci[\"Country\"].map(c_to_iso)\n",
    "iso_to_research_eci = dict(research_eci.values)\n",
    "df[\"research_eci_2020\"] = df[\"iso2_code\"].map(iso_to_research_eci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "df.to_csv(\"../outputs/eci_comparisons_2020.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 3 - software space from relatedness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgelist_cleaning_for_software_space(data, key_columns):\n",
    "    \"\"\"get software space network from raw proximity values\"\"\"\n",
    "    data = data[key_columns]\n",
    "\n",
    "    # drop zero -- non-existing edges\n",
    "    data = data[data[key_columns[2]] > 0]\n",
    "\n",
    "    # drop self loops\n",
    "    data = data[data[key_columns[0]] != data[key_columns[1]]]\n",
    "    return data\n",
    "\n",
    "def maximum_spanning_tree(data, key_columns):\n",
    "    \"\"\"get the maximum spanning tree of the full relatedness based network\"\"\"\n",
    "    table = data.copy()\n",
    "    table[\"distance\"] = 1.0 / table[key_columns[2]]\n",
    "    G = nx.from_pandas_edgelist(table, source = key_columns[0], target = key_columns[1], edge_attr = [\"distance\", key_columns[2]])\n",
    "    T = nx.minimum_spanning_tree(G, weight = \"distance\")\n",
    "    table2 = nx.to_pandas_edgelist(T)\n",
    "    table2 = table2[table2[key_columns[2]] > 0]\n",
    "    table2.rename(columns = {\"source\": key_columns[0], \"target\": key_columns[1], key_columns[2]: \"score\"}, inplace = True)\n",
    "    table = pd.merge(\n",
    "        table,\n",
    "        table2,\n",
    "        on=key_columns[0:2]\n",
    "    )  \n",
    "    table[\"edge\"] = table.apply(lambda x: \"%s-%s\" % (min(x[key_columns[0]], x[key_columns[1]]), max(x[key_columns[0]], x[key_columns[1]])), axis = 1)\n",
    "    table = table.drop_duplicates(subset = [\"edge\"])\n",
    "    table = table.drop(\"edge\", 1)\n",
    "    return table[key_columns]\n",
    "\n",
    "def add_edges(mst_edges, all_edges, nr_edges_to_add):\n",
    "    \"\"\"add edges to the maximum spanning tree to have a 1/3 nodes/edges ratio\"\"\"\n",
    "    # drop mst edges from the full edgelist\n",
    "    mst_edges[\"drop\"] = 1\n",
    "    all_edges = pd.merge(\n",
    "        all_edges,\n",
    "        mst_edges,\n",
    "        on = [\"language_1\", \"language_2\", \"proximity\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    all_edges = all_edges[all_edges[\"drop\"] != 1].drop(columns=\"drop\")\n",
    "\n",
    "    # sort and select\n",
    "    all_edges = all_edges.sort_values(by=\"proximity\", ascending=False).iloc[:nr_edges_to_add]\n",
    "\n",
    "    # add to mst edgelist\n",
    "    software_space_el = pd.concat([mst_edges, all_edges])\n",
    "    return software_space_el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/4036771504.py:28: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  table = table.drop(\"edge\", 1)\n"
     ]
    }
   ],
   "source": [
    "# from relatedness table to software space (MST w/ additional edges)\n",
    "space_table = edgelist_cleaning_for_software_space(rel_df, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_el = maximum_spanning_tree(space_table, key_columns=[\"language_1\", \"language_2\", \"proximity\"])\n",
    "mst_graph = nx.from_pandas_edgelist(mst_el, source=\"language_1\", target=\"language_2\")\n",
    "n_nodes = mst_graph.number_of_nodes()\n",
    "n_edges = n_nodes * 2\n",
    "software_space_el = add_edges(mst_el, space_table, nr_edges_to_add=n_edges)\n",
    "\n",
    "# export final software space edgelist\n",
    "software_space_el.to_csv(\"../outputs/software_space_edgelist_2020_2021_based.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 4 - regression data for cross-sectional entry models (2022-2023)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle cleaned data for M_cl -- 3 : 2022 / 4 : 2023\n",
    "dfb3 = bundle_data(df, periods=[3])\n",
    "dfb4 = bundle_data(df, periods=[4])\n",
    "dfb3[\"period\"] = 3\n",
    "dfb4[\"period\"] = 4\n",
    "dfbs = pd.concat([dfb3, dfb4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rca_calculation(table, c_column, p_column, value_column):\n",
    "    \"\"\"calculate RCA from an M_cp dataframe\"\"\"\n",
    "    table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
    "    table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
    "    table[\"e\"] = table[value_column].sum()\n",
    "\n",
    "    table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
    "    table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_p\"] = table.groupby(p_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e_c\"] = table.groupby(c_column)[value_column].transform(\"sum\")\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"e\"] = table[value_column].sum()\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca\"] = (table[value_column] / table[\"e_p\"]) / (table[\"e_c\"] / table[\"e\"])\n",
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_92093/172238313.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table[\"rca01\"] = np.where(table[\"rca\"] >= 1, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "# calculate RCA for each period\n",
    "rca_tables = list()\n",
    "for p in dfbs[\"period\"].unique():\n",
    "    rca_df = dfbs[dfbs[\"period\"]==p]\n",
    "    rca_tables.append(rca_calculation(rca_df, c_column=\"iso2_code\", p_column=\"language\", value_column=\"num_pushers\"))\n",
    "rca_tables = pd.concat(rca_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify entry following the given patterns\n",
    "entry_pattern = [0,1]\n",
    "consider_pattern = [0,0]\n",
    "ent = rca_tables.sort_values([\"period\"], ascending=True).groupby([\"iso2_code\",\"language\"])[\"rca01\"].agg(list).reset_index()\n",
    "ent[\"entry01\"] = ent[\"rca01\"].apply(lambda x: x == entry_pattern).astype(int)\n",
    "ent[\"consider00\"] = ent[\"rca01\"].apply(lambda x: x == consider_pattern).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full combination\n",
    "all_countries = ent[\"iso2_code\"].unique()\n",
    "all_languages = ent[\"language\"].unique()\n",
    "\n",
    "all_combinations = list(product(all_countries, all_languages))\n",
    "full_df = pd.DataFrame(all_combinations, columns=[\"iso2_code\", \"language\"])\\\n",
    "    .sort_values([\"iso2_code\", \"language\"])\n",
    "\n",
    "# join entries\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    ent[[\"iso2_code\", \"language\", \"entry01\", \"consider00\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ").fillna(0)\n",
    "\n",
    "# join complexity\n",
    "# cdf = pd.read_csv(\"../outputs/complexity_table2020.csv\", sep=\";\")\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    cdf[[\"iso2_code\", \"language\", \"pci\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# join RCA from the baseline period\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df[\"rca01\"] = full_df[\"rca01\"].fillna(0)\n",
    "\n",
    "# drop languages with no complexity value\n",
    "full_df.dropna(subset=[\"pci\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate relatedness ddensity \n",
    "# software_space_el = pd.read_csv(\"../outputs/software_space_edgelist_2020_2021_based.csv\", sep=\";\")\n",
    "software_space_el[\"proximity\"] = 1\n",
    "\n",
    "# symmetric relatedness matrix\n",
    "relatedness = pd.pivot_table(\n",
    "    software_space_el,\n",
    "    values=\"proximity\",\n",
    "    index=[\"language_1\"],\n",
    "    columns=[\"language_2\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ")\n",
    "relatedness = relatedness.combine_first(relatedness.T).fillna(0).astype(int)\n",
    "\n",
    "# matrix from RCA values in the baseline period\n",
    "rca_tables = rca_tables[rca_tables[\"language\"].isin(relatedness.columns)]\n",
    "mat = pd.pivot_table(\n",
    "    rca_tables[rca_tables[\"period\"]==3].loc[:,[\"iso2_code\", \"language\", \"rca01\"]],\n",
    "    values=\"rca01\",\n",
    "    index=[\"iso2_code\"],\n",
    "    columns=[\"language\"],\n",
    "    aggfunc=np.sum,\n",
    "    margins=False\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "# relatedness density\n",
    "rel = np.dot(mat, relatedness)\n",
    "reltot = np.sum(relatedness, axis=0)\n",
    "reltot = reltot.values.flatten()\n",
    "reldens = rel / reltot\n",
    "reldens_df = pd.DataFrame(reldens)\n",
    "reldens_df.index = mat.index\n",
    "reldens_df\n",
    "reldens_df.columns = mat.columns\n",
    "reldens_df = reldens_df.rename_axis(\"iso2_code\")\\\n",
    "  .reset_index()\\\n",
    "  .melt(\"iso2_code\", value_name=\"rel_density\", var_name=\"language\")\\\n",
    "  .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join to full_df with entries and PCI\n",
    "full_df = pd.merge(\n",
    "    full_df,\n",
    "    reldens_df,\n",
    "    on=[\"iso2_code\", \"language\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export for entry models -- only consider 00, 01 patterns\n",
    "full_df[\"entry01\"] = full_df[\"entry01\"].astype(int)\n",
    "full_df[\"consider00\"] = full_df[\"consider00\"].astype(int)\n",
    "export_df = full_df[(full_df[\"entry01\"]==1) | (full_df[\"consider00\"]==1)]\n",
    "export_df.to_csv(\"../outputs/data_entry_regressions_2020_2021_based.csv\", index=False, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 5 - data for ECI related regressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9d/8j37_fks51x11mk0_zwqsd940000gn/T/ipykernel_96448/1367150806.py:2: DtypeWarning: Columns (40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trade_df = pd.read_csv(\"../data/Gravity_V202211.csv\")\n"
     ]
    }
   ],
   "source": [
    "# data from CEPII -- http://www.cepii.fr/CEPII/en/bdd_modele/bdd_modele_item.asp?id=8\n",
    "trade_df = pd.read_csv(\"../data/Gravity_V202211.csv\")\n",
    "trade_df = trade_df[trade_df[\"year\"] == 2020]\n",
    "trade_df['country_id_o'] = trade_df['country_id_o'].map(lambda x: x.replace('.2',''))\n",
    "trade_df['country_id_d'] = trade_df['country_id_d'].map(lambda x: x.replace('.2',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>country_id_o</th>\n",
       "      <th>country_id_d</th>\n",
       "      <th>iso3_o</th>\n",
       "      <th>iso3_d</th>\n",
       "      <th>iso3num_o</th>\n",
       "      <th>iso3num_d</th>\n",
       "      <th>country_exists_o</th>\n",
       "      <th>country_exists_d</th>\n",
       "      <th>gmt_offset_2020_o</th>\n",
       "      <th>...</th>\n",
       "      <th>entry_time_o</th>\n",
       "      <th>entry_time_d</th>\n",
       "      <th>entry_tp_o</th>\n",
       "      <th>entry_tp_d</th>\n",
       "      <th>tradeflow_comtrade_o</th>\n",
       "      <th>tradeflow_comtrade_d</th>\n",
       "      <th>tradeflow_baci</th>\n",
       "      <th>manuf_tradeflow_baci</th>\n",
       "      <th>tradeflow_imf_o</th>\n",
       "      <th>tradeflow_imf_d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2020</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>ABW</td>\n",
       "      <td>533.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2020</td>\n",
       "      <td>ABW</td>\n",
       "      <td>AFG</td>\n",
       "      <td>ABW</td>\n",
       "      <td>AFG</td>\n",
       "      <td>533.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year country_id_o country_id_d iso3_o iso3_d  iso3num_o  iso3num_d  \\\n",
       "72   2020          ABW          ABW    ABW    ABW      533.0      533.0   \n",
       "146  2020          ABW          AFG    ABW    AFG      533.0        4.0   \n",
       "\n",
       "     country_exists_o  country_exists_d  gmt_offset_2020_o  ...  entry_time_o  \\\n",
       "72                  1                 1               -4.0  ...           NaN   \n",
       "146                 1                 1               -4.0  ...           NaN   \n",
       "\n",
       "     entry_time_d  entry_tp_o  entry_tp_d  tradeflow_comtrade_o  \\\n",
       "72            NaN         NaN         NaN                   NaN   \n",
       "146           NaN         NaN         NaN                   NaN   \n",
       "\n",
       "     tradeflow_comtrade_d tradeflow_baci manuf_tradeflow_baci  \\\n",
       "72                    NaN            NaN                  NaN   \n",
       "146                   NaN            NaN                  NaN   \n",
       "\n",
       "     tradeflow_imf_o  tradeflow_imf_d  \n",
       "72               NaN              NaN  \n",
       "146              NaN              NaN  \n",
       "\n",
       "[2 rows x 87 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"year\",\n",
    "    \"country_id_o\",\n",
    "    \"country_id_d\",\n",
    "    \"iso3_o\",\n",
    "    \"iso3_d\",\n",
    "    #\"tradeflow_baci\",\n",
    "    \"gmt_offset_2020_o\",\n",
    "    \"gmt_offset_2020_d\",\n",
    "    \"distw_harmonic\",\n",
    "    \"dist\",\n",
    "    \"scaled_sci_2021\",\n",
    "    \"pop_o\",\n",
    "    \"pop_d\",\n",
    "    \"gdp_o\",\n",
    "    \"gdp_d\",\n",
    "    \"gdpcap_o\",\n",
    "    \"gdpcap_d\",\n",
    "    \"gdp_ppp_o\",\n",
    "    \"gdp_ppp_d\",\n",
    "    \"gdpcap_ppp_o\",\n",
    "    \"gdpcap_ppp_d\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.read_csv(\"../outputs/software_complexity_2020_2021_based.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso2_code</th>\n",
       "      <th>language</th>\n",
       "      <th>num_pushers</th>\n",
       "      <th>period</th>\n",
       "      <th>diversity</th>\n",
       "      <th>ubiquity</th>\n",
       "      <th>mcp</th>\n",
       "      <th>eci</th>\n",
       "      <th>pci</th>\n",
       "      <th>density</th>\n",
       "      <th>coi</th>\n",
       "      <th>cog</th>\n",
       "      <th>rca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE</td>\n",
       "      <td>AIDL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.17948</td>\n",
       "      <td>1.964787</td>\n",
       "      <td>0.036024</td>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.746792</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE</td>\n",
       "      <td>AMPL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.17948</td>\n",
       "      <td>2.611604</td>\n",
       "      <td>0.020808</td>\n",
       "      <td>-0.177167</td>\n",
       "      <td>1.201992</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  iso2_code language  num_pushers  period  diversity  ubiquity  mcp      eci  \\\n",
       "0        AE     AIDL            0       1         19         8    0 -0.17948   \n",
       "1        AE     AMPL            0       1         19         7    0 -0.17948   \n",
       "\n",
       "        pci   density       coi       cog  rca  \n",
       "0  1.964787  0.036024 -0.177167  0.746792  0.0  \n",
       "1  2.611604  0.020808 -0.177167  1.201992  0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
